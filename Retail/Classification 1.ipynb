{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container{width:90% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np; import pandas as pd; import pyodbc; import datetime; import sklearn; import os; import math\n",
    "from sklearn.feature_selection import chi2, f_classif, SelectKBest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "%pylab inline \n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from IPython.core.display import display,HTML\n",
    "display(HTML(\"<style>.container{width:90% !important;}</style>\"))\n",
    "\n",
    "conn = pyodbc.connect(r'DRIVER={SQL Server Native Client 11.0};'r'SERVER=WIN-5G5AUOCEJPK;'r'DATABASE=Gold585;'r'Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query =\"SELECT [PurchaseDate] \\\n",
    "      ,MONTH(GETDATE()) MesPrognoza\\\n",
    "      ,[PartnerID] \\\n",
    "      ,IIF(DATEDIFF(YEAR,[BirthDate],GETDATE())> 100 , 0 , DATEDIFF(YEAR,[BirthDate],GETDATE())) Age \\\n",
    "      ,IIF(SEX='M',1,0) SEX \\\n",
    "      ,CityID \\\n",
    "      ,SMS \\\n",
    "      ,SUMSMS \\\n",
    "      ,SumQuantity \\\n",
    "      ,[PurchaseCode] \\\n",
    "      ,[SummaAfterDiscount] \\\n",
    "      ,[FirstVisit] \\\n",
    "      ,DATEDIFF(DAY,[FirstVisit],GETDATE())/30.0 LT_M \\\n",
    "      ,DATEDIFF(DAY,[FirstVisit],GETDATE())/30.0 LastVisit_M \\\n",
    "      ,[NEXTDate] \\\n",
    "      ,DATEDIFF(DAY,GETDATE(),NEXTDate) PridetCherez \\\n",
    "      ,IIF(DATEDIFF(DAY,GETDATE(),NEXTDate)<=31,1,0) PridetCherez_M \\\n",
    "      ,IIF(NEXTDate IS NULL,1,0) Ottok \\\n",
    "      ,[GodNazad] \\\n",
    "      ,[QNTVisits] \\\n",
    "      ,[SUMM1] \\\n",
    "      ,[SUMM2] \\\n",
    "      ,[SUMM3] \\\n",
    "      ,[SUMM4] \\\n",
    "      ,[SUMM5] \\\n",
    "      ,[SUMM6] \\\n",
    "      ,[SUMM7] \\\n",
    "      ,[SUMM8] \\\n",
    "      ,[SUMM9] \\\n",
    "      ,[SUMM10] \\\n",
    "      ,[SUMM11] \\\n",
    "      ,[SUMM12] \\\n",
    "      ,[SumSumma] \\\n",
    "      ,[AVGSumma] \\\n",
    "      ,[SUMP1k] \\\n",
    "      ,[SUMP3k] \\\n",
    "      ,[SUMP6k] \\\n",
    "      ,[SUMP12k] \\\n",
    "      ,[SUMP50k] \\\n",
    "      ,[PriceGroup] \\\n",
    "      ,[MaterialID] \\\n",
    "      ,[Name] \\\n",
    "      ,[GroupID] \\\n",
    "      ,[CollectionID] \\\n",
    "      ,[SUMKolco] \\\n",
    "      ,[SUMSERGI] \\\n",
    "      ,[SUMPPODVES] \\\n",
    "      ,[SUMCEP] \\\n",
    "      ,[SUMBRASLET] \\\n",
    "      ,[SUMKOLE] \\\n",
    "      ,[WearType] \\\n",
    "      ,[SUMCheap] \\\n",
    "      ,[SUMExpensive] \\\n",
    "      ,[SUMPremium] \\\n",
    "      ,[SUMMiddle] \\\n",
    "      ,[PriceSegment] \\\n",
    "      ,[SUMZoloto] \\\n",
    "      ,[SUMSerebro] \\\n",
    "      ,[Metal] \\\n",
    "      ,[SUMColorBlack] \\\n",
    "      ,[SUMColorRed] \\\n",
    "      ,[SUMColorYellow] \\\n",
    "      ,[SUMColorWhite] \\\n",
    "      ,[SUMColor3] \\\n",
    "      ,[SUMColor2] \\\n",
    "      ,[MetalColor] \\\n",
    "      ,[SUMGroupBaza] \\\n",
    "      ,[SUMGroupClassic] \\\n",
    "      ,[SUMGroupModa] \\\n",
    "      ,[SUMGroupModul] \\\n",
    "      ,[SUMGroupSouvenir] \\\n",
    "      ,[SUMGroupTrend]  \\\n",
    "      ,[StylisticGroup] \\\n",
    "  FROM [Gold585].[dbo].[ForPredict] \\\n",
    "  WHERE [Metal] in ('ЗОЛОТО','СЕРЕБРО') and QNTVisits > 2\"\n",
    "\n",
    "df = pd.read_sql(sql_query,conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PurchaseDate</th>\n",
       "      <th>MesPrognoza</th>\n",
       "      <th>PartnerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CityID</th>\n",
       "      <th>SMS</th>\n",
       "      <th>SUMSMS</th>\n",
       "      <th>SumQuantity</th>\n",
       "      <th>PurchaseCode</th>\n",
       "      <th>...</th>\n",
       "      <th>SUMColor3</th>\n",
       "      <th>SUMColor2</th>\n",
       "      <th>MetalColor</th>\n",
       "      <th>SUMGroupBaza</th>\n",
       "      <th>SUMGroupClassic</th>\n",
       "      <th>SUMGroupModa</th>\n",
       "      <th>SUMGroupModul</th>\n",
       "      <th>SUMGroupSouvenir</th>\n",
       "      <th>SUMGroupTrend</th>\n",
       "      <th>StylisticGroup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>10</td>\n",
       "      <td>567512</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1125499734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>КРАСНЫЙ</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>КЛАССИКА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>10</td>\n",
       "      <td>572549</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>1217563616</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>КРАСНЫЙ</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>БАЗА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>10</td>\n",
       "      <td>2256871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1129516545</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>КРАСНЫЙ</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>КЛАССИКА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-09</td>\n",
       "      <td>10</td>\n",
       "      <td>593619</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1209140210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>БЕЛЫЙ</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>БАЗА</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-03-06</td>\n",
       "      <td>10</td>\n",
       "      <td>1458477</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>1036396482</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2ХЦВЕТН</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>КЛАССИКА</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PurchaseDate  MesPrognoza PartnerID  Age  SEX  CityID  SMS  SUMSMS  \\\n",
       "0   2015-12-27           10    567512   30    1      92    0       0   \n",
       "1   2018-09-01           10    572549   35    1      92    0      12   \n",
       "2   2016-03-01           10   2256871    0    0      90    0       0   \n",
       "3   2018-05-09           10    593619   46    0      92    0       0   \n",
       "4   2015-03-06           10   1458477   24    0     115    0       0   \n",
       "\n",
       "   SumQuantity PurchaseCode       ...        SUMColor3 SUMColor2  MetalColor  \\\n",
       "0            5   1125499734       ...                0         0     КРАСНЫЙ   \n",
       "1           40   1217563616       ...                0         0     КРАСНЫЙ   \n",
       "2            6   1129516545       ...                4         0     КРАСНЫЙ   \n",
       "3            6   1209140210       ...                0         0       БЕЛЫЙ   \n",
       "4           84   1036396482       ...                0         3     2ХЦВЕТН   \n",
       "\n",
       "   SUMGroupBaza SUMGroupClassic  SUMGroupModa  SUMGroupModul  \\\n",
       "0             1               4             0              0   \n",
       "1             0              32             8              0   \n",
       "2             2               4             0              0   \n",
       "3             1               3             2              0   \n",
       "4            21              60             0              0   \n",
       "\n",
       "   SUMGroupSouvenir  SUMGroupTrend  StylisticGroup  \n",
       "0                 0              0        КЛАССИКА  \n",
       "1                 0              0            БАЗА  \n",
       "2                 0              0        КЛАССИКА  \n",
       "3                 0              0            БАЗА  \n",
       "4                 0              0        КЛАССИКА  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PurchaseDate', 'MesPrognoza', 'PartnerID', 'Age', 'SEX', 'CityID',\n",
       "       'SMS', 'SUMSMS', 'SumQuantity', 'PurchaseCode', 'SummaAfterDiscount',\n",
       "       'FirstVisit', 'LT_M', 'LastVisit_M', 'NEXTDate', 'PridetCherez',\n",
       "       'PridetCherez_M', 'Ottok', 'GodNazad', 'QNTVisits', 'SUMM1', 'SUMM2',\n",
       "       'SUMM3', 'SUMM4', 'SUMM5', 'SUMM6', 'SUMM7', 'SUMM8', 'SUMM9', 'SUMM10',\n",
       "       'SUMM11', 'SUMM12', 'SumSumma', 'AVGSumma', 'SUMP1k', 'SUMP3k',\n",
       "       'SUMP6k', 'SUMP12k', 'SUMP50k', 'PriceGroup', 'MaterialID', 'Name',\n",
       "       'GroupID', 'CollectionID', 'SUMKolco', 'SUMSERGI', 'SUMPPODVES',\n",
       "       'SUMCEP', 'SUMBRASLET', 'SUMKOLE', 'WearType', 'SUMCheap',\n",
       "       'SUMExpensive', 'SUMPremium', 'SUMMiddle', 'PriceSegment', 'SUMZoloto',\n",
       "       'SUMSerebro', 'Metal', 'SUMColorBlack', 'SUMColorRed', 'SUMColorYellow',\n",
       "       'SUMColorWhite', 'SUMColor3', 'SUMColor2', 'MetalColor', 'SUMGroupBaza',\n",
       "       'SUMGroupClassic', 'SUMGroupModa', 'SUMGroupModul', 'SUMGroupSouvenir',\n",
       "       'SUMGroupTrend', 'StylisticGroup'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Прогнозируем металл\n",
    "data1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.drop(['MesPrognoza','PurchaseDate','PurchaseCode','SummaAfterDiscount','FirstVisit','NEXTDate',\n",
    "       'PridetCherez', 'PridetCherez_M', 'Ottok','PriceGroup', 'MaterialID',\n",
    "       'Name', 'GroupID', 'CollectionID','WearType','PriceSegment', 'MetalColor','StylisticGroup'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartnerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CityID</th>\n",
       "      <th>SMS</th>\n",
       "      <th>SUMSMS</th>\n",
       "      <th>SumQuantity</th>\n",
       "      <th>LT_M</th>\n",
       "      <th>LastVisit_M</th>\n",
       "      <th>GodNazad</th>\n",
       "      <th>...</th>\n",
       "      <th>SUMColorYellow</th>\n",
       "      <th>SUMColorWhite</th>\n",
       "      <th>SUMColor3</th>\n",
       "      <th>SUMColor2</th>\n",
       "      <th>SUMGroupBaza</th>\n",
       "      <th>SUMGroupClassic</th>\n",
       "      <th>SUMGroupModa</th>\n",
       "      <th>SUMGroupModul</th>\n",
       "      <th>SUMGroupSouvenir</th>\n",
       "      <th>SUMGroupTrend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567512</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66.100000</td>\n",
       "      <td>66.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572549</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2256871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593619</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1458477</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>46.366666</td>\n",
       "      <td>46.366666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PartnerID  Age  SEX  CityID  SMS  SUMSMS  SumQuantity       LT_M  \\\n",
       "0    567512   30    1      92    0       0            5  66.100000   \n",
       "1    572549   35    1      92    0      12           40  60.500000   \n",
       "2   2256871    0    0      90    0       0            6  34.200000   \n",
       "3    593619   46    0      92    0       0            6  22.200000   \n",
       "4   1458477   24    0     115    0       0           84  46.366666   \n",
       "\n",
       "   LastVisit_M  GodNazad      ...        SUMColorYellow  SUMColorWhite  \\\n",
       "0    66.100000       0.0      ...                     0              0   \n",
       "1    60.500000       0.0      ...                     0              0   \n",
       "2    34.200000       0.0      ...                     0              2   \n",
       "3    22.200000       0.0      ...                     0              6   \n",
       "4    46.366666       0.0      ...                     0              3   \n",
       "\n",
       "   SUMColor3  SUMColor2  SUMGroupBaza  SUMGroupClassic  SUMGroupModa  \\\n",
       "0          0          0             1                4             0   \n",
       "1          0          0             0               32             8   \n",
       "2          4          0             2                4             0   \n",
       "3          0          0             1                3             2   \n",
       "4          0          3            21               60             0   \n",
       "\n",
       "   SUMGroupModul  SUMGroupSouvenir  SUMGroupTrend  \n",
       "0              0                 0              0  \n",
       "1              0                 0              0  \n",
       "2              0                 0              0  \n",
       "3              0                 0              0  \n",
       "4              0                 0              0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PartnerID', 'Age', 'SEX', 'CityID', 'SMS', 'SUMSMS', 'SumQuantity',\n",
       "       'LT_M', 'LastVisit_M', 'GodNazad', 'QNTVisits', 'SUMM1', 'SUMM2',\n",
       "       'SUMM3', 'SUMM4', 'SUMM5', 'SUMM6', 'SUMM7', 'SUMM8', 'SUMM9', 'SUMM10',\n",
       "       'SUMM11', 'SUMM12', 'SumSumma', 'AVGSumma', 'SUMP1k', 'SUMP3k',\n",
       "       'SUMP6k', 'SUMP12k', 'SUMP50k', 'SUMKolco', 'SUMSERGI', 'SUMPPODVES',\n",
       "       'SUMCEP', 'SUMBRASLET', 'SUMKOLE', 'SUMCheap', 'SUMExpensive',\n",
       "       'SUMPremium', 'SUMMiddle', 'SUMZoloto', 'SUMSerebro', 'Metal',\n",
       "       'SUMColorBlack', 'SUMColorRed', 'SUMColorYellow', 'SUMColorWhite',\n",
       "       'SUMColor3', 'SUMColor2', 'SUMGroupBaza', 'SUMGroupClassic',\n",
       "       'SUMGroupModa', 'SUMGroupModul', 'SUMGroupSouvenir', 'SUMGroupTrend'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CityID</th>\n",
       "      <th>SMS</th>\n",
       "      <th>SUMSMS</th>\n",
       "      <th>SumQuantity</th>\n",
       "      <th>LT_M</th>\n",
       "      <th>LastVisit_M</th>\n",
       "      <th>GodNazad</th>\n",
       "      <th>QNTVisits</th>\n",
       "      <th>...</th>\n",
       "      <th>SUMColorYellow</th>\n",
       "      <th>SUMColorWhite</th>\n",
       "      <th>SUMColor3</th>\n",
       "      <th>SUMColor2</th>\n",
       "      <th>SUMGroupBaza</th>\n",
       "      <th>SUMGroupClassic</th>\n",
       "      <th>SUMGroupModa</th>\n",
       "      <th>SUMGroupModul</th>\n",
       "      <th>SUMGroupSouvenir</th>\n",
       "      <th>SUMGroupTrend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.094881e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "      <td>2.120002e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.866967e+01</td>\n",
       "      <td>2.540752e-01</td>\n",
       "      <td>7.104584e+01</td>\n",
       "      <td>1.489848e-01</td>\n",
       "      <td>3.318987e+00</td>\n",
       "      <td>1.948183e+02</td>\n",
       "      <td>3.860953e+01</td>\n",
       "      <td>3.860953e+01</td>\n",
       "      <td>1.494825e-01</td>\n",
       "      <td>1.946720e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>3.881916e-01</td>\n",
       "      <td>2.692868e+01</td>\n",
       "      <td>4.366689e-01</td>\n",
       "      <td>1.412290e+01</td>\n",
       "      <td>4.933680e+01</td>\n",
       "      <td>1.381567e+02</td>\n",
       "      <td>3.885524e+00</td>\n",
       "      <td>1.643934e+00</td>\n",
       "      <td>4.650510e-01</td>\n",
       "      <td>2.426101e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.619384e+01</td>\n",
       "      <td>4.353402e-01</td>\n",
       "      <td>3.377768e+01</td>\n",
       "      <td>3.560735e-01</td>\n",
       "      <td>1.265798e+02</td>\n",
       "      <td>5.080544e+03</td>\n",
       "      <td>1.748818e+01</td>\n",
       "      <td>1.748818e+01</td>\n",
       "      <td>3.565635e-01</td>\n",
       "      <td>5.080118e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>9.983399e+00</td>\n",
       "      <td>6.056525e+02</td>\n",
       "      <td>9.828585e+00</td>\n",
       "      <td>3.790246e+02</td>\n",
       "      <td>1.314535e+03</td>\n",
       "      <td>3.681113e+03</td>\n",
       "      <td>5.770013e+01</td>\n",
       "      <td>2.386816e+01</td>\n",
       "      <td>9.427608e+00</td>\n",
       "      <td>5.597139e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.333330e-01</td>\n",
       "      <td>1.333330e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.600000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.326667e+01</td>\n",
       "      <td>2.326667e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.906667e+01</td>\n",
       "      <td>3.906667e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.200000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>5.346667e+01</td>\n",
       "      <td>5.346667e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.800000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.280000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.470000e+04</td>\n",
       "      <td>3.705600e+05</td>\n",
       "      <td>7.056667e+01</td>\n",
       "      <td>7.056667e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>3.705600e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>4.339200e+04</td>\n",
       "      <td>7.680000e+02</td>\n",
       "      <td>2.880000e+04</td>\n",
       "      <td>9.715200e+04</td>\n",
       "      <td>2.674560e+05</td>\n",
       "      <td>3.456000e+03</td>\n",
       "      <td>1.536000e+03</td>\n",
       "      <td>5.760000e+02</td>\n",
       "      <td>5.500000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Age           SEX        CityID           SMS        SUMSMS  \\\n",
       "count  2.120002e+06  2.120002e+06  2.120002e+06  2.120002e+06  2.120002e+06   \n",
       "mean   3.866967e+01  2.540752e-01  7.104584e+01  1.489848e-01  3.318987e+00   \n",
       "std    1.619384e+01  4.353402e-01  3.377768e+01  3.560735e-01  1.265798e+02   \n",
       "min    0.000000e+00  0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    2.900000e+01  0.000000e+00  3.600000e+01  0.000000e+00  0.000000e+00   \n",
       "50%    3.800000e+01  0.000000e+00  8.000000e+01  0.000000e+00  0.000000e+00   \n",
       "75%    5.000000e+01  1.000000e+00  9.200000e+01  0.000000e+00  0.000000e+00   \n",
       "max    1.000000e+02  1.000000e+00  1.280000e+02  1.000000e+00  1.470000e+04   \n",
       "\n",
       "        SumQuantity          LT_M   LastVisit_M      GodNazad     QNTVisits  \\\n",
       "count  2.120002e+06  2.120002e+06  2.120002e+06  2.094881e+06  2.120002e+06   \n",
       "mean   1.948183e+02  3.860953e+01  3.860953e+01  1.494825e-01  1.946720e+02   \n",
       "std    5.080544e+03  1.748818e+01  1.748818e+01  3.565635e-01  5.080118e+03   \n",
       "min    3.000000e+00  1.333330e-01  1.333330e-01  0.000000e+00  3.000000e+00   \n",
       "25%    4.000000e+00  2.326667e+01  2.326667e+01  0.000000e+00  4.000000e+00   \n",
       "50%    8.000000e+00  3.906667e+01  3.906667e+01  0.000000e+00  8.000000e+00   \n",
       "75%    1.800000e+01  5.346667e+01  5.346667e+01  0.000000e+00  1.800000e+01   \n",
       "max    3.705600e+05  7.056667e+01  7.056667e+01  1.000000e+00  3.705600e+05   \n",
       "\n",
       "           ...        SUMColorYellow  SUMColorWhite     SUMColor3  \\\n",
       "count      ...          2.120002e+06   2.120002e+06  2.120002e+06   \n",
       "mean       ...          3.881916e-01   2.692868e+01  4.366689e-01   \n",
       "std        ...          9.983399e+00   6.056525e+02  9.828585e+00   \n",
       "min        ...          0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "25%        ...          0.000000e+00   0.000000e+00  0.000000e+00   \n",
       "50%        ...          0.000000e+00   1.000000e+00  0.000000e+00   \n",
       "75%        ...          0.000000e+00   4.000000e+00  0.000000e+00   \n",
       "max        ...          7.680000e+02   4.339200e+04  7.680000e+02   \n",
       "\n",
       "          SUMColor2  SUMGroupBaza  SUMGroupClassic  SUMGroupModa  \\\n",
       "count  2.120002e+06  2.120002e+06     2.120002e+06  2.120002e+06   \n",
       "mean   1.412290e+01  4.933680e+01     1.381567e+02  3.885524e+00   \n",
       "std    3.790246e+02  1.314535e+03     3.681113e+03  5.770013e+01   \n",
       "min    0.000000e+00  0.000000e+00     0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00     2.000000e+00  0.000000e+00   \n",
       "50%    0.000000e+00  2.000000e+00     4.000000e+00  0.000000e+00   \n",
       "75%    2.000000e+00  4.000000e+00     1.100000e+01  1.000000e+00   \n",
       "max    2.880000e+04  9.715200e+04     2.674560e+05  3.456000e+03   \n",
       "\n",
       "       SUMGroupModul  SUMGroupSouvenir  SUMGroupTrend  \n",
       "count   2.120002e+06      2.120002e+06   2.120002e+06  \n",
       "mean    1.643934e+00      4.650510e-01   2.426101e-01  \n",
       "std     2.386816e+01      9.427608e+00   5.597139e+00  \n",
       "min     0.000000e+00      0.000000e+00   0.000000e+00  \n",
       "25%     0.000000e+00      0.000000e+00   0.000000e+00  \n",
       "50%     0.000000e+00      0.000000e+00   0.000000e+00  \n",
       "75%     0.000000e+00      0.000000e+00   0.000000e+00  \n",
       "max     1.536000e+03      5.760000e+02   5.500000e+02  \n",
       "\n",
       "[8 rows x 53 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2120002, 55)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126.0\n",
      "638872.0000000001\n"
     ]
    }
   ],
   "source": [
    "print(data1['QNTVisits'].quantile(0.95))\n",
    "print(data1['SumSumma'].quantile(0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1[data1['QNTVisits']<126.0]\n",
    "data1 = data1[data1['QNTVisits']<638872.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013940, 55)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Metal'].replace('ЗОЛОТО' ,0,inplace=True)\n",
    "data1['Metal'].replace('СЕРЕБРО',1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1312681\n",
       "1     701259\n",
       "Name: Metal, dtype: int64"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1['Metal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data1, columns = ['SEX','CityID'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= pd.concat([data,data[data['Metal']==1]],axis=0,ignore_index=True) # добавляем меньшего класса - делаем балансировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_comp = 5\n",
    "data = data.fillna(0)\n",
    "# tSVD\n",
    "tsvd = TruncatedSVD(n_components=n_comp, random_state=420)\n",
    "tsvd_results_train = tsvd.fit_transform(data.drop([\"Metal\",'PartnerID'], axis=1))\n",
    "# PCA\n",
    "pca = PCA(n_components=n_comp, random_state=420)\n",
    "pca2_results_train = pca.fit_transform(data.drop([\"Metal\",'PartnerID'], axis=1))\n",
    "# ICA\n",
    "ica = FastICA(n_components=n_comp, random_state=420)\n",
    "ica2_results_train = ica.fit_transform(data.drop([\"Metal\",'PartnerID'], axis=1))\n",
    "# GRP\n",
    "grp = GaussianRandomProjection(n_components=n_comp, eps=0.1, random_state=420)\n",
    "grp_results_train = grp.fit_transform(data.drop([\"Metal\",'PartnerID'], axis=1))\n",
    "# SRP\n",
    "srp = SparseRandomProjection(n_components=n_comp, dense_output=True, random_state=420)\n",
    "srp_results_train = srp.fit_transform(data.drop([\"Metal\",'PartnerID'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PartnerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>SMS</th>\n",
       "      <th>SUMSMS</th>\n",
       "      <th>SumQuantity</th>\n",
       "      <th>LT_M</th>\n",
       "      <th>LastVisit_M</th>\n",
       "      <th>GodNazad</th>\n",
       "      <th>QNTVisits</th>\n",
       "      <th>SUMM1</th>\n",
       "      <th>...</th>\n",
       "      <th>pca_4</th>\n",
       "      <th>ica_4</th>\n",
       "      <th>tsvd_4</th>\n",
       "      <th>grp_4</th>\n",
       "      <th>srp_4</th>\n",
       "      <th>pca_5</th>\n",
       "      <th>ica_5</th>\n",
       "      <th>tsvd_5</th>\n",
       "      <th>grp_5</th>\n",
       "      <th>srp_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567512</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>66.100000</td>\n",
       "      <td>66.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.525243</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>23.072030</td>\n",
       "      <td>335.548107</td>\n",
       "      <td>10638.243471</td>\n",
       "      <td>-13.498367</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>-20.175292</td>\n",
       "      <td>-14422.100263</td>\n",
       "      <td>-63.162850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572549</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>60.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.201938</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>0.438910</td>\n",
       "      <td>25269.625492</td>\n",
       "      <td>6484.962183</td>\n",
       "      <td>-12.573303</td>\n",
       "      <td>-0.000399</td>\n",
       "      <td>-24.932579</td>\n",
       "      <td>-51996.003143</td>\n",
       "      <td>-183.010308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2256871</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.344599</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>4.565296</td>\n",
       "      <td>1813.412338</td>\n",
       "      <td>12386.396807</td>\n",
       "      <td>-37.239086</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>-29.533838</td>\n",
       "      <td>-19180.922133</td>\n",
       "      <td>-12.956482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593619</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6.192477</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>-5.918693</td>\n",
       "      <td>108.670079</td>\n",
       "      <td>1037.058415</td>\n",
       "      <td>11.919980</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>21.347749</td>\n",
       "      <td>-1640.637653</td>\n",
       "      <td>-84.217133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1458477</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>46.366666</td>\n",
       "      <td>46.366666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.128498</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-44.807614</td>\n",
       "      <td>45624.632167</td>\n",
       "      <td>5424.747056</td>\n",
       "      <td>-29.038318</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-51.437111</td>\n",
       "      <td>-85860.615141</td>\n",
       "      <td>-276.944803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  PartnerID  Age  SMS  SUMSMS  SumQuantity       LT_M  LastVisit_M  GodNazad  \\\n",
       "0    567512   30    0       0            5  66.100000    66.100000       0.0   \n",
       "1    572549   35    0      12           40  60.500000    60.500000       0.0   \n",
       "2   2256871    0    0       0            6  34.200000    34.200000       0.0   \n",
       "3    593619   46    0       0            6  22.200000    22.200000       0.0   \n",
       "4   1458477   24    0       0           84  46.366666    46.366666       0.0   \n",
       "\n",
       "   QNTVisits  SUMM1     ...          pca_4     ica_4     tsvd_4         grp_4  \\\n",
       "0          5      0     ...       7.525243 -0.001199  23.072030    335.548107   \n",
       "1         40      4     ...     -15.201938 -0.001009   0.438910  25269.625492   \n",
       "2          6      0     ...       2.344599  0.000058   4.565296   1813.412338   \n",
       "3          6      2     ...       6.192477  0.000710  -5.918693    108.670079   \n",
       "4         81     21     ...     -63.128498 -0.000594 -44.807614  45624.632167   \n",
       "\n",
       "          srp_4      pca_5     ica_5     tsvd_5         grp_5       srp_5  \n",
       "0  10638.243471 -13.498367  0.000409 -20.175292 -14422.100263  -63.162850  \n",
       "1   6484.962183 -12.573303 -0.000399 -24.932579 -51996.003143 -183.010308  \n",
       "2  12386.396807 -37.239086  0.000187 -29.533838 -19180.922133  -12.956482  \n",
       "3   1037.058415  11.919980  0.000152  21.347749  -1640.637653  -84.217133  \n",
       "4   5424.747056 -29.038318 -0.000941 -51.437111 -85860.615141 -276.944803  \n",
       "\n",
       "[5 rows x 199 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append decomposition components to datasets\n",
    "for i in range(1, n_comp + 1):\n",
    "    data['pca_' + str(i)] = pca2_results_train[:, i - 1]\n",
    "\n",
    "    data['ica_' + str(i)] = ica2_results_train[:, i - 1]\n",
    "\n",
    "    data['tsvd_' + str(i)] = tsvd_results_train[:, i - 1]\n",
    "\n",
    "    data['grp_' + str(i)] = grp_results_train[:, i - 1]\n",
    "\n",
    "    data['srp_' + str(i)] = srp_results_train[:, i - 1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Metal',axis=1).fillna(0)\n",
    "y = data['Metal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "Xn = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013940, 173)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013940,)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xn, y, test_size=0.25, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.90      0.88    328170\n",
      "          1       0.79      0.73      0.76    175315\n",
      "\n",
      "avg / total       0.83      0.84      0.84    503485\n",
      "\n",
      "[[294027  34143]\n",
      " [ 47968 127347]]\n",
      "0.8111745263915885\n",
      "Wall time: 23min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# fit a CART model to the data\n",
    "ExTC = ExtraTreesClassifier(n_jobs=-1,max_features='log2',class_weight='balanced',n_estimators=500 )\n",
    "param_grid = { \n",
    "    'n_estimators': [50],\n",
    "    'class_weight':['balanced'],\n",
    "   # 'max_depth' : [2,200,1000],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "model = GridSearchCV(estimator=ExTC, param_grid=param_grid, cv= 5)\n",
    "model.fit(X_train, y_train)\n",
    "#print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))\n",
    "#ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xdfa0fdea90>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(ExTC.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(15).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-19 11:29:07.393494\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "print(now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:45:32] Tree method is automatically selected to be 'approx' for faster speed. to use old behavior(exact greedy algorithm on single machine), set tree_method to 'exact'\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.94      0.83   1145035\n",
      "          1       0.68      0.29      0.41    525378\n",
      "\n",
      "avg / total       0.72      0.73      0.70   1670413\n",
      "\n",
      "[[1072449   72586]\n",
      " [ 370848  154530]]\n",
      "0.6153695670227713\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "# Setting some parameters\n",
    "\n",
    "parameters = {\n",
    " #   'eta': 0.3,  \n",
    "    'silent': True,  # option for logging\n",
    "#    'objective': 'multi:softprob',  # error evaluation for multiclass tasks\n",
    "    'num_class': 2  # number of classes to predic\n",
    "#    ,'max_depth': 3  # depth of the trees in the boosting process\n",
    "    }  \n",
    "num_round = 200  # the number of training iterations\n",
    "#training the model\n",
    "bst = xgb.train(parameters, dtrain, num_round)\n",
    "#resut\n",
    "predicted = bst.predict(dtest)\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8024974762560062\n"
     ]
    }
   ],
   "source": [
    "test_probs = model.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, test_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7103618934313884\n"
     ]
    }
   ],
   "source": [
    "test_probs2 = model.predict(X_test)\n",
    "print(roc_auc_score(y_test, test_probs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=30)]: Done  17 out of  50 | elapsed: 28.3min remaining: 54.9min\n",
      "[Parallel(n_jobs=30)]: Done  43 out of  50 | elapsed: 49.3min remaining:  8.0min\n",
      "[Parallel(n_jobs=30)]: Done  50 out of  50 | elapsed: 50.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw AUC score: 0.80788344703518\n",
      "colsample_bytree: 0.6\n",
      "learning_rate: 0.01\n",
      "max_depth: 20\n",
      "min_child_weight: 11\n",
      "missing: -9\n",
      "n_estimators: 50\n",
      "nthread: 3\n",
      "objective: 'binary:logistic'\n",
      "seed: 1337\n",
      "silent: 1\n",
      "subsample: 0.8\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'preds_class' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-557b01ac9598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Проверка модели\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_class\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preds_class' is not defined"
     ]
    }
   ],
   "source": [
    "%time\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "parameters = {'nthread':[3,4,5],\n",
    "              'objective':['binary:logistic'],\n",
    "              'learning_rate':[0.01], \n",
    "              'max_depth': [10,12,14,20],\n",
    "              'min_child_weight': [11],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7,0.8],\n",
    "              'colsample_bytree': [0.6],\n",
    "              'n_estimators': [50],\n",
    "              'missing':[-9],\n",
    "              'seed': [1337]}\n",
    "\n",
    "\n",
    "clf = RandomizedSearchCV(xgb_model, parameters, n_jobs=30, \n",
    "                   cv=StratifiedKFold(y_train, n_folds=5, shuffle=True), \n",
    "                   scoring='roc_auc',\n",
    "                   verbose=2, refit=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "best_parameters, score, _ = max(clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Raw AUC score:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Проверка модели\n",
    "test_probs = clf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, test_probs))\n",
    "test_probs2 = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, test_probs2))\n",
    "\n",
    "print(metrics.classification_report(y_test, test_probs2))\n",
    "print(metrics.confusion_matrix(y_test, test_probs2))\n",
    "print(roc_auc_score(y_test, test_probs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.811451160454299\n",
      "0.7143896022004622\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.90      0.84    412957\n",
      "          1       0.73      0.53      0.61    215492\n",
      "\n",
      "avg / total       0.77      0.77      0.76    628449\n",
      "\n",
      "[[371379  41578]\n",
      " [101397 114095]]\n",
      "0.7143896022004622\n"
     ]
    }
   ],
   "source": [
    "test_probs = clf.predict_proba(X_test)[:,1]\n",
    "print(roc_auc_score(y_test, test_probs))\n",
    "test_probs2 = clf.predict(X_test)\n",
    "print(roc_auc_score(y_test, test_probs2))\n",
    "\n",
    "print(metrics.classification_report(y_test, test_probs2))\n",
    "print(metrics.confusion_matrix(y_test, test_probs2))\n",
    "print(roc_auc_score(y_test, test_probs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3996384402962994e+24\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "print(reg.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.132988\n",
      "0:\tlearn: 0.6498896\ttotal: 3.05s\tremaining: 50m 49s\n",
      "1:\tlearn: 0.6182309\ttotal: 5.99s\tremaining: 49m 46s\n",
      "2:\tlearn: 0.5946717\ttotal: 8.91s\tremaining: 49m 21s\n",
      "3:\tlearn: 0.5773377\ttotal: 11.9s\tremaining: 49m 16s\n",
      "4:\tlearn: 0.5642877\ttotal: 14.8s\tremaining: 49m 13s\n",
      "5:\tlearn: 0.5544349\ttotal: 17.8s\tremaining: 49m 16s\n",
      "6:\tlearn: 0.5469088\ttotal: 20.8s\tremaining: 49m 12s\n",
      "7:\tlearn: 0.5411687\ttotal: 23.8s\tremaining: 49m 9s\n",
      "8:\tlearn: 0.5366285\ttotal: 26.7s\tremaining: 49m 4s\n",
      "9:\tlearn: 0.5331064\ttotal: 29.7s\tremaining: 49m\n",
      "10:\tlearn: 0.5303348\ttotal: 32.6s\tremaining: 48m 50s\n",
      "11:\tlearn: 0.5281654\ttotal: 35.5s\tremaining: 48m 42s\n",
      "12:\tlearn: 0.5264513\ttotal: 38.4s\tremaining: 48m 33s\n",
      "13:\tlearn: 0.5250039\ttotal: 41.3s\tremaining: 48m 30s\n",
      "14:\tlearn: 0.5238201\ttotal: 44.3s\tremaining: 48m 26s\n",
      "15:\tlearn: 0.5228863\ttotal: 47.2s\tremaining: 48m 20s\n",
      "16:\tlearn: 0.5221295\ttotal: 50.1s\tremaining: 48m 14s\n",
      "17:\tlearn: 0.5214660\ttotal: 53s\tremaining: 48m 11s\n",
      "18:\tlearn: 0.5208927\ttotal: 55.9s\tremaining: 48m 6s\n",
      "19:\tlearn: 0.5201976\ttotal: 58.8s\tremaining: 48m 1s\n",
      "20:\tlearn: 0.5196087\ttotal: 1m 1s\tremaining: 47m 57s\n",
      "21:\tlearn: 0.5192014\ttotal: 1m 4s\tremaining: 47m 54s\n",
      "22:\tlearn: 0.5188565\ttotal: 1m 7s\tremaining: 47m 51s\n",
      "23:\tlearn: 0.5184591\ttotal: 1m 10s\tremaining: 47m 47s\n",
      "24:\tlearn: 0.5181539\ttotal: 1m 13s\tremaining: 47m 45s\n",
      "25:\tlearn: 0.5178475\ttotal: 1m 16s\tremaining: 47m 42s\n",
      "26:\tlearn: 0.5175714\ttotal: 1m 19s\tremaining: 47m 40s\n",
      "27:\tlearn: 0.5172959\ttotal: 1m 22s\tremaining: 47m 38s\n",
      "28:\tlearn: 0.5171270\ttotal: 1m 25s\tremaining: 47m 35s\n",
      "29:\tlearn: 0.5169308\ttotal: 1m 28s\tremaining: 47m 32s\n",
      "30:\tlearn: 0.5167332\ttotal: 1m 31s\tremaining: 47m 29s\n",
      "31:\tlearn: 0.5165917\ttotal: 1m 34s\tremaining: 47m 26s\n",
      "32:\tlearn: 0.5163109\ttotal: 1m 37s\tremaining: 47m 23s\n",
      "33:\tlearn: 0.5161598\ttotal: 1m 39s\tremaining: 47m 19s\n",
      "34:\tlearn: 0.5160204\ttotal: 1m 42s\tremaining: 47m 17s\n",
      "35:\tlearn: 0.5158707\ttotal: 1m 45s\tremaining: 47m 14s\n",
      "36:\tlearn: 0.5157539\ttotal: 1m 48s\tremaining: 47m 13s\n",
      "37:\tlearn: 0.5156142\ttotal: 1m 51s\tremaining: 47m 10s\n",
      "38:\tlearn: 0.5155027\ttotal: 1m 54s\tremaining: 47m 8s\n",
      "39:\tlearn: 0.5153326\ttotal: 1m 57s\tremaining: 47m 6s\n",
      "40:\tlearn: 0.5151542\ttotal: 2m\tremaining: 47m 2s\n",
      "41:\tlearn: 0.5150636\ttotal: 2m 3s\tremaining: 46m 59s\n",
      "42:\tlearn: 0.5149510\ttotal: 2m 6s\tremaining: 46m 57s\n",
      "43:\tlearn: 0.5148608\ttotal: 2m 9s\tremaining: 46m 55s\n",
      "44:\tlearn: 0.5147799\ttotal: 2m 12s\tremaining: 46m 53s\n",
      "45:\tlearn: 0.5146910\ttotal: 2m 15s\tremaining: 46m 50s\n",
      "46:\tlearn: 0.5145957\ttotal: 2m 18s\tremaining: 46m 48s\n",
      "47:\tlearn: 0.5145312\ttotal: 2m 21s\tremaining: 46m 46s\n",
      "48:\tlearn: 0.5143762\ttotal: 2m 24s\tremaining: 46m 43s\n",
      "49:\tlearn: 0.5142154\ttotal: 2m 27s\tremaining: 46m 39s\n",
      "50:\tlearn: 0.5141252\ttotal: 2m 30s\tremaining: 46m 37s\n",
      "51:\tlearn: 0.5140580\ttotal: 2m 33s\tremaining: 46m 34s\n",
      "52:\tlearn: 0.5139766\ttotal: 2m 36s\tremaining: 46m 31s\n",
      "53:\tlearn: 0.5138744\ttotal: 2m 39s\tremaining: 46m 28s\n",
      "54:\tlearn: 0.5137965\ttotal: 2m 42s\tremaining: 46m 25s\n",
      "55:\tlearn: 0.5137215\ttotal: 2m 45s\tremaining: 46m 21s\n",
      "56:\tlearn: 0.5136358\ttotal: 2m 47s\tremaining: 46m 19s\n",
      "57:\tlearn: 0.5135656\ttotal: 2m 50s\tremaining: 46m 16s\n",
      "58:\tlearn: 0.5135109\ttotal: 2m 53s\tremaining: 46m 13s\n",
      "59:\tlearn: 0.5134316\ttotal: 2m 56s\tremaining: 46m 10s\n",
      "60:\tlearn: 0.5133644\ttotal: 2m 59s\tremaining: 46m 7s\n",
      "61:\tlearn: 0.5132921\ttotal: 3m 2s\tremaining: 46m 4s\n",
      "62:\tlearn: 0.5132213\ttotal: 3m 5s\tremaining: 46m 1s\n",
      "63:\tlearn: 0.5131723\ttotal: 3m 8s\tremaining: 45m 59s\n",
      "64:\tlearn: 0.5130253\ttotal: 3m 11s\tremaining: 45m 55s\n",
      "65:\tlearn: 0.5129877\ttotal: 3m 14s\tremaining: 45m 52s\n",
      "66:\tlearn: 0.5128940\ttotal: 3m 17s\tremaining: 45m 49s\n",
      "67:\tlearn: 0.5128177\ttotal: 3m 20s\tremaining: 45m 47s\n",
      "68:\tlearn: 0.5127021\ttotal: 3m 23s\tremaining: 45m 44s\n",
      "69:\tlearn: 0.5126124\ttotal: 3m 26s\tremaining: 45m 41s\n",
      "70:\tlearn: 0.5125720\ttotal: 3m 29s\tremaining: 45m 39s\n",
      "71:\tlearn: 0.5125251\ttotal: 3m 32s\tremaining: 45m 36s\n",
      "72:\tlearn: 0.5124669\ttotal: 3m 35s\tremaining: 45m 34s\n",
      "73:\tlearn: 0.5124133\ttotal: 3m 38s\tremaining: 45m 32s\n",
      "74:\tlearn: 0.5123653\ttotal: 3m 41s\tremaining: 45m 30s\n",
      "75:\tlearn: 0.5122759\ttotal: 3m 44s\tremaining: 45m 27s\n",
      "76:\tlearn: 0.5122171\ttotal: 3m 47s\tremaining: 45m 24s\n",
      "77:\tlearn: 0.5121575\ttotal: 3m 50s\tremaining: 45m 21s\n",
      "78:\tlearn: 0.5120955\ttotal: 3m 53s\tremaining: 45m 18s\n",
      "79:\tlearn: 0.5120553\ttotal: 3m 56s\tremaining: 45m 15s\n",
      "80:\tlearn: 0.5120177\ttotal: 3m 59s\tremaining: 45m 12s\n",
      "81:\tlearn: 0.5119724\ttotal: 4m 2s\tremaining: 45m 9s\n",
      "82:\tlearn: 0.5119140\ttotal: 4m 4s\tremaining: 45m 6s\n",
      "83:\tlearn: 0.5118737\ttotal: 4m 7s\tremaining: 45m 3s\n",
      "84:\tlearn: 0.5117697\ttotal: 4m 10s\tremaining: 45m\n",
      "85:\tlearn: 0.5116767\ttotal: 4m 13s\tremaining: 44m 57s\n",
      "86:\tlearn: 0.5116431\ttotal: 4m 16s\tremaining: 44m 54s\n",
      "87:\tlearn: 0.5115823\ttotal: 4m 19s\tremaining: 44m 51s\n",
      "88:\tlearn: 0.5115482\ttotal: 4m 22s\tremaining: 44m 48s\n",
      "89:\tlearn: 0.5115101\ttotal: 4m 25s\tremaining: 44m 46s\n",
      "90:\tlearn: 0.5114691\ttotal: 4m 28s\tremaining: 44m 43s\n",
      "91:\tlearn: 0.5114108\ttotal: 4m 31s\tremaining: 44m 39s\n",
      "92:\tlearn: 0.5113862\ttotal: 4m 34s\tremaining: 44m 37s\n",
      "93:\tlearn: 0.5113517\ttotal: 4m 37s\tremaining: 44m 34s\n",
      "94:\tlearn: 0.5112825\ttotal: 4m 40s\tremaining: 44m 31s\n",
      "95:\tlearn: 0.5112539\ttotal: 4m 43s\tremaining: 44m 28s\n",
      "96:\tlearn: 0.5112184\ttotal: 4m 46s\tremaining: 44m 26s\n",
      "97:\tlearn: 0.5111902\ttotal: 4m 49s\tremaining: 44m 23s\n",
      "98:\tlearn: 0.5111609\ttotal: 4m 52s\tremaining: 44m 19s\n",
      "99:\tlearn: 0.5110937\ttotal: 4m 55s\tremaining: 44m 16s\n",
      "100:\tlearn: 0.5110547\ttotal: 4m 58s\tremaining: 44m 13s\n",
      "101:\tlearn: 0.5109824\ttotal: 5m 1s\tremaining: 44m 10s\n",
      "102:\tlearn: 0.5109377\ttotal: 5m 3s\tremaining: 44m 6s\n",
      "103:\tlearn: 0.5108644\ttotal: 5m 6s\tremaining: 44m 3s\n",
      "104:\tlearn: 0.5108393\ttotal: 5m 9s\tremaining: 44m\n",
      "105:\tlearn: 0.5108042\ttotal: 5m 12s\tremaining: 43m 57s\n",
      "106:\tlearn: 0.5107632\ttotal: 5m 15s\tremaining: 43m 54s\n",
      "107:\tlearn: 0.5107256\ttotal: 5m 18s\tremaining: 43m 51s\n",
      "108:\tlearn: 0.5106684\ttotal: 5m 21s\tremaining: 43m 48s\n",
      "109:\tlearn: 0.5106254\ttotal: 5m 24s\tremaining: 43m 45s\n",
      "110:\tlearn: 0.5105942\ttotal: 5m 27s\tremaining: 43m 43s\n",
      "111:\tlearn: 0.5105532\ttotal: 5m 30s\tremaining: 43m 40s\n",
      "112:\tlearn: 0.5105247\ttotal: 5m 33s\tremaining: 43m 37s\n",
      "113:\tlearn: 0.5104481\ttotal: 5m 36s\tremaining: 43m 35s\n",
      "114:\tlearn: 0.5104043\ttotal: 5m 39s\tremaining: 43m 32s\n",
      "115:\tlearn: 0.5103759\ttotal: 5m 42s\tremaining: 43m 29s\n",
      "116:\tlearn: 0.5103532\ttotal: 5m 45s\tremaining: 43m 26s\n",
      "117:\tlearn: 0.5103145\ttotal: 5m 48s\tremaining: 43m 24s\n",
      "118:\tlearn: 0.5102803\ttotal: 5m 51s\tremaining: 43m 21s\n",
      "119:\tlearn: 0.5102499\ttotal: 5m 54s\tremaining: 43m 17s\n",
      "120:\tlearn: 0.5102191\ttotal: 5m 57s\tremaining: 43m 14s\n",
      "121:\tlearn: 0.5101415\ttotal: 6m\tremaining: 43m 11s\n",
      "122:\tlearn: 0.5101147\ttotal: 6m 3s\tremaining: 43m 8s\n",
      "123:\tlearn: 0.5100877\ttotal: 6m 6s\tremaining: 43m 6s\n",
      "124:\tlearn: 0.5100672\ttotal: 6m 9s\tremaining: 43m 3s\n",
      "125:\tlearn: 0.5100264\ttotal: 6m 12s\tremaining: 43m\n",
      "126:\tlearn: 0.5099963\ttotal: 6m 15s\tremaining: 42m 58s\n",
      "127:\tlearn: 0.5099668\ttotal: 6m 18s\tremaining: 42m 55s\n",
      "128:\tlearn: 0.5099216\ttotal: 6m 21s\tremaining: 42m 52s\n",
      "129:\tlearn: 0.5098966\ttotal: 6m 24s\tremaining: 42m 50s\n",
      "130:\tlearn: 0.5098572\ttotal: 6m 27s\tremaining: 42m 47s\n",
      "131:\tlearn: 0.5098320\ttotal: 6m 30s\tremaining: 42m 44s\n",
      "132:\tlearn: 0.5098031\ttotal: 6m 32s\tremaining: 42m 41s\n",
      "133:\tlearn: 0.5097818\ttotal: 6m 35s\tremaining: 42m 38s\n",
      "134:\tlearn: 0.5097534\ttotal: 6m 38s\tremaining: 42m 35s\n",
      "135:\tlearn: 0.5097185\ttotal: 6m 41s\tremaining: 42m 33s\n",
      "136:\tlearn: 0.5096886\ttotal: 6m 44s\tremaining: 42m 30s\n",
      "137:\tlearn: 0.5096429\ttotal: 6m 47s\tremaining: 42m 27s\n",
      "138:\tlearn: 0.5095958\ttotal: 6m 50s\tremaining: 42m 24s\n",
      "139:\tlearn: 0.5095710\ttotal: 6m 53s\tremaining: 42m 21s\n",
      "140:\tlearn: 0.5095277\ttotal: 6m 56s\tremaining: 42m 18s\n",
      "141:\tlearn: 0.5095052\ttotal: 6m 59s\tremaining: 42m 14s\n",
      "142:\tlearn: 0.5094708\ttotal: 7m 2s\tremaining: 42m 11s\n",
      "143:\tlearn: 0.5094445\ttotal: 7m 5s\tremaining: 42m 8s\n",
      "144:\tlearn: 0.5094090\ttotal: 7m 8s\tremaining: 42m 5s\n",
      "145:\tlearn: 0.5093777\ttotal: 7m 11s\tremaining: 42m 2s\n",
      "146:\tlearn: 0.5093255\ttotal: 7m 14s\tremaining: 41m 59s\n",
      "147:\tlearn: 0.5092972\ttotal: 7m 17s\tremaining: 41m 56s\n",
      "148:\tlearn: 0.5092758\ttotal: 7m 20s\tremaining: 41m 53s\n",
      "149:\tlearn: 0.5092546\ttotal: 7m 23s\tremaining: 41m 50s\n",
      "150:\tlearn: 0.5092091\ttotal: 7m 26s\tremaining: 41m 47s\n",
      "151:\tlearn: 0.5091839\ttotal: 7m 29s\tremaining: 41m 45s\n",
      "152:\tlearn: 0.5091615\ttotal: 7m 32s\tremaining: 41m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153:\tlearn: 0.5091334\ttotal: 7m 34s\tremaining: 41m 39s\n",
      "154:\tlearn: 0.5090813\ttotal: 7m 37s\tremaining: 41m 36s\n",
      "155:\tlearn: 0.5090489\ttotal: 7m 40s\tremaining: 41m 33s\n",
      "156:\tlearn: 0.5090136\ttotal: 7m 43s\tremaining: 41m 30s\n",
      "157:\tlearn: 0.5089846\ttotal: 7m 46s\tremaining: 41m 27s\n",
      "158:\tlearn: 0.5089624\ttotal: 7m 49s\tremaining: 41m 24s\n",
      "159:\tlearn: 0.5089370\ttotal: 7m 52s\tremaining: 41m 22s\n",
      "160:\tlearn: 0.5088990\ttotal: 7m 55s\tremaining: 41m 18s\n",
      "161:\tlearn: 0.5088776\ttotal: 7m 58s\tremaining: 41m 15s\n",
      "162:\tlearn: 0.5088491\ttotal: 8m 1s\tremaining: 41m 12s\n",
      "163:\tlearn: 0.5088307\ttotal: 8m 4s\tremaining: 41m 9s\n",
      "164:\tlearn: 0.5087789\ttotal: 8m 7s\tremaining: 41m 6s\n",
      "165:\tlearn: 0.5087311\ttotal: 8m 10s\tremaining: 41m 3s\n",
      "166:\tlearn: 0.5086856\ttotal: 8m 13s\tremaining: 41m\n",
      "167:\tlearn: 0.5086523\ttotal: 8m 16s\tremaining: 40m 57s\n",
      "168:\tlearn: 0.5086159\ttotal: 8m 19s\tremaining: 40m 55s\n",
      "169:\tlearn: 0.5085754\ttotal: 8m 22s\tremaining: 40m 52s\n",
      "170:\tlearn: 0.5085475\ttotal: 8m 25s\tremaining: 40m 49s\n",
      "171:\tlearn: 0.5085194\ttotal: 8m 28s\tremaining: 40m 46s\n",
      "172:\tlearn: 0.5084981\ttotal: 8m 31s\tremaining: 40m 43s\n",
      "173:\tlearn: 0.5084330\ttotal: 8m 34s\tremaining: 40m 40s\n",
      "174:\tlearn: 0.5083946\ttotal: 8m 37s\tremaining: 40m 37s\n",
      "175:\tlearn: 0.5083560\ttotal: 8m 40s\tremaining: 40m 34s\n",
      "176:\tlearn: 0.5083429\ttotal: 8m 43s\tremaining: 40m 32s\n",
      "177:\tlearn: 0.5083083\ttotal: 8m 46s\tremaining: 40m 29s\n",
      "178:\tlearn: 0.5082669\ttotal: 8m 49s\tremaining: 40m 26s\n",
      "179:\tlearn: 0.5082377\ttotal: 8m 52s\tremaining: 40m 23s\n",
      "180:\tlearn: 0.5082175\ttotal: 8m 54s\tremaining: 40m 20s\n",
      "181:\tlearn: 0.5082002\ttotal: 8m 57s\tremaining: 40m 17s\n",
      "182:\tlearn: 0.5081658\ttotal: 9m\tremaining: 40m 14s\n",
      "183:\tlearn: 0.5081407\ttotal: 9m 3s\tremaining: 40m 11s\n",
      "184:\tlearn: 0.5081209\ttotal: 9m 6s\tremaining: 40m 8s\n",
      "185:\tlearn: 0.5080763\ttotal: 9m 9s\tremaining: 40m 5s\n",
      "186:\tlearn: 0.5080341\ttotal: 9m 12s\tremaining: 40m 3s\n",
      "187:\tlearn: 0.5079794\ttotal: 9m 15s\tremaining: 40m\n",
      "188:\tlearn: 0.5079515\ttotal: 9m 18s\tremaining: 39m 57s\n",
      "189:\tlearn: 0.5079343\ttotal: 9m 21s\tremaining: 39m 54s\n",
      "190:\tlearn: 0.5079186\ttotal: 9m 24s\tremaining: 39m 51s\n",
      "191:\tlearn: 0.5078947\ttotal: 9m 27s\tremaining: 39m 48s\n",
      "192:\tlearn: 0.5078706\ttotal: 9m 30s\tremaining: 39m 45s\n",
      "193:\tlearn: 0.5078462\ttotal: 9m 33s\tremaining: 39m 42s\n",
      "194:\tlearn: 0.5077991\ttotal: 9m 36s\tremaining: 39m 39s\n",
      "195:\tlearn: 0.5077832\ttotal: 9m 39s\tremaining: 39m 36s\n",
      "196:\tlearn: 0.5077573\ttotal: 9m 42s\tremaining: 39m 33s\n",
      "197:\tlearn: 0.5077392\ttotal: 9m 45s\tremaining: 39m 30s\n",
      "198:\tlearn: 0.5077205\ttotal: 9m 48s\tremaining: 39m 27s\n",
      "199:\tlearn: 0.5077063\ttotal: 9m 51s\tremaining: 39m 24s\n",
      "200:\tlearn: 0.5076838\ttotal: 9m 54s\tremaining: 39m 21s\n",
      "201:\tlearn: 0.5076450\ttotal: 9m 57s\tremaining: 39m 18s\n",
      "202:\tlearn: 0.5076156\ttotal: 9m 59s\tremaining: 39m 15s\n",
      "203:\tlearn: 0.5076012\ttotal: 10m 2s\tremaining: 39m 12s\n",
      "204:\tlearn: 0.5075694\ttotal: 10m 5s\tremaining: 39m 10s\n",
      "205:\tlearn: 0.5075458\ttotal: 10m 9s\tremaining: 39m 7s\n",
      "206:\tlearn: 0.5075269\ttotal: 10m 11s\tremaining: 39m 4s\n",
      "207:\tlearn: 0.5075067\ttotal: 10m 14s\tremaining: 39m 1s\n",
      "208:\tlearn: 0.5074904\ttotal: 10m 17s\tremaining: 38m 58s\n",
      "209:\tlearn: 0.5074614\ttotal: 10m 20s\tremaining: 38m 55s\n",
      "210:\tlearn: 0.5074355\ttotal: 10m 23s\tremaining: 38m 52s\n",
      "211:\tlearn: 0.5074132\ttotal: 10m 26s\tremaining: 38m 49s\n",
      "212:\tlearn: 0.5073853\ttotal: 10m 29s\tremaining: 38m 46s\n",
      "213:\tlearn: 0.5073671\ttotal: 10m 32s\tremaining: 38m 43s\n",
      "214:\tlearn: 0.5073513\ttotal: 10m 35s\tremaining: 38m 40s\n",
      "215:\tlearn: 0.5073246\ttotal: 10m 38s\tremaining: 38m 38s\n",
      "216:\tlearn: 0.5073076\ttotal: 10m 41s\tremaining: 38m 34s\n",
      "217:\tlearn: 0.5072907\ttotal: 10m 44s\tremaining: 38m 31s\n",
      "218:\tlearn: 0.5072681\ttotal: 10m 47s\tremaining: 38m 28s\n",
      "219:\tlearn: 0.5072459\ttotal: 10m 50s\tremaining: 38m 25s\n",
      "220:\tlearn: 0.5072203\ttotal: 10m 53s\tremaining: 38m 22s\n",
      "221:\tlearn: 0.5072000\ttotal: 10m 56s\tremaining: 38m 19s\n",
      "222:\tlearn: 0.5071821\ttotal: 10m 59s\tremaining: 38m 16s\n",
      "223:\tlearn: 0.5071586\ttotal: 11m 2s\tremaining: 38m 13s\n",
      "224:\tlearn: 0.5071350\ttotal: 11m 5s\tremaining: 38m 10s\n",
      "225:\tlearn: 0.5071079\ttotal: 11m 8s\tremaining: 38m 7s\n",
      "226:\tlearn: 0.5070825\ttotal: 11m 11s\tremaining: 38m 5s\n",
      "227:\tlearn: 0.5070523\ttotal: 11m 14s\tremaining: 38m 2s\n",
      "228:\tlearn: 0.5070344\ttotal: 11m 16s\tremaining: 37m 59s\n",
      "229:\tlearn: 0.5070129\ttotal: 11m 19s\tremaining: 37m 56s\n",
      "230:\tlearn: 0.5069907\ttotal: 11m 22s\tremaining: 37m 53s\n",
      "231:\tlearn: 0.5069464\ttotal: 11m 25s\tremaining: 37m 50s\n",
      "232:\tlearn: 0.5069167\ttotal: 11m 28s\tremaining: 37m 47s\n",
      "233:\tlearn: 0.5068956\ttotal: 11m 31s\tremaining: 37m 44s\n",
      "234:\tlearn: 0.5068695\ttotal: 11m 34s\tremaining: 37m 41s\n",
      "235:\tlearn: 0.5068445\ttotal: 11m 37s\tremaining: 37m 38s\n",
      "236:\tlearn: 0.5068162\ttotal: 11m 40s\tremaining: 37m 35s\n",
      "237:\tlearn: 0.5067818\ttotal: 11m 43s\tremaining: 37m 32s\n",
      "238:\tlearn: 0.5067576\ttotal: 11m 46s\tremaining: 37m 29s\n",
      "239:\tlearn: 0.5067362\ttotal: 11m 49s\tremaining: 37m 26s\n",
      "240:\tlearn: 0.5067172\ttotal: 11m 52s\tremaining: 37m 23s\n",
      "241:\tlearn: 0.5066903\ttotal: 11m 55s\tremaining: 37m 20s\n",
      "242:\tlearn: 0.5066634\ttotal: 11m 58s\tremaining: 37m 17s\n",
      "243:\tlearn: 0.5066447\ttotal: 12m 1s\tremaining: 37m 14s\n",
      "244:\tlearn: 0.5065974\ttotal: 12m 4s\tremaining: 37m 11s\n",
      "245:\tlearn: 0.5065576\ttotal: 12m 7s\tremaining: 37m 8s\n",
      "246:\tlearn: 0.5065303\ttotal: 12m 9s\tremaining: 37m 5s\n",
      "247:\tlearn: 0.5065015\ttotal: 12m 12s\tremaining: 37m 2s\n",
      "248:\tlearn: 0.5064553\ttotal: 12m 15s\tremaining: 36m 59s\n",
      "249:\tlearn: 0.5064375\ttotal: 12m 18s\tremaining: 36m 56s\n",
      "250:\tlearn: 0.5064168\ttotal: 12m 21s\tremaining: 36m 53s\n",
      "251:\tlearn: 0.5064013\ttotal: 12m 24s\tremaining: 36m 50s\n",
      "252:\tlearn: 0.5063836\ttotal: 12m 27s\tremaining: 36m 47s\n",
      "253:\tlearn: 0.5063694\ttotal: 12m 30s\tremaining: 36m 44s\n",
      "254:\tlearn: 0.5063439\ttotal: 12m 33s\tremaining: 36m 41s\n",
      "255:\tlearn: 0.5063155\ttotal: 12m 36s\tremaining: 36m 38s\n",
      "256:\tlearn: 0.5062882\ttotal: 12m 39s\tremaining: 36m 35s\n",
      "257:\tlearn: 0.5062708\ttotal: 12m 42s\tremaining: 36m 32s\n",
      "258:\tlearn: 0.5062542\ttotal: 12m 45s\tremaining: 36m 29s\n",
      "259:\tlearn: 0.5062357\ttotal: 12m 48s\tremaining: 36m 27s\n",
      "260:\tlearn: 0.5062170\ttotal: 12m 51s\tremaining: 36m 23s\n",
      "261:\tlearn: 0.5061964\ttotal: 12m 54s\tremaining: 36m 20s\n",
      "262:\tlearn: 0.5061870\ttotal: 12m 57s\tremaining: 36m 18s\n",
      "263:\tlearn: 0.5061713\ttotal: 13m\tremaining: 36m 15s\n",
      "264:\tlearn: 0.5061507\ttotal: 13m 3s\tremaining: 36m 12s\n",
      "265:\tlearn: 0.5061291\ttotal: 13m 6s\tremaining: 36m 9s\n",
      "266:\tlearn: 0.5061032\ttotal: 13m 9s\tremaining: 36m 6s\n",
      "267:\tlearn: 0.5060877\ttotal: 13m 12s\tremaining: 36m 3s\n",
      "268:\tlearn: 0.5060649\ttotal: 13m 15s\tremaining: 36m\n",
      "269:\tlearn: 0.5060375\ttotal: 13m 18s\tremaining: 35m 57s\n",
      "270:\tlearn: 0.5060186\ttotal: 13m 21s\tremaining: 35m 54s\n",
      "271:\tlearn: 0.5059996\ttotal: 13m 23s\tremaining: 35m 51s\n",
      "272:\tlearn: 0.5059776\ttotal: 13m 26s\tremaining: 35m 48s\n",
      "273:\tlearn: 0.5059575\ttotal: 13m 29s\tremaining: 35m 45s\n",
      "274:\tlearn: 0.5059282\ttotal: 13m 32s\tremaining: 35m 42s\n",
      "275:\tlearn: 0.5059087\ttotal: 13m 35s\tremaining: 35m 39s\n",
      "276:\tlearn: 0.5058886\ttotal: 13m 38s\tremaining: 35m 36s\n",
      "277:\tlearn: 0.5058707\ttotal: 13m 41s\tremaining: 35m 33s\n",
      "278:\tlearn: 0.5058512\ttotal: 13m 44s\tremaining: 35m 30s\n",
      "279:\tlearn: 0.5058286\ttotal: 13m 47s\tremaining: 35m 27s\n",
      "280:\tlearn: 0.5058037\ttotal: 13m 50s\tremaining: 35m 24s\n",
      "281:\tlearn: 0.5057871\ttotal: 13m 53s\tremaining: 35m 21s\n",
      "282:\tlearn: 0.5057639\ttotal: 13m 56s\tremaining: 35m 18s\n",
      "283:\tlearn: 0.5057216\ttotal: 13m 59s\tremaining: 35m 15s\n",
      "284:\tlearn: 0.5056923\ttotal: 14m 2s\tremaining: 35m 12s\n",
      "285:\tlearn: 0.5056739\ttotal: 14m 5s\tremaining: 35m 9s\n",
      "286:\tlearn: 0.5056509\ttotal: 14m 8s\tremaining: 35m 7s\n",
      "287:\tlearn: 0.5056313\ttotal: 14m 11s\tremaining: 35m 4s\n",
      "288:\tlearn: 0.5056162\ttotal: 14m 14s\tremaining: 35m 1s\n",
      "289:\tlearn: 0.5055970\ttotal: 14m 17s\tremaining: 34m 58s\n",
      "290:\tlearn: 0.5055802\ttotal: 14m 20s\tremaining: 34m 55s\n",
      "291:\tlearn: 0.5055592\ttotal: 14m 22s\tremaining: 34m 52s\n",
      "292:\tlearn: 0.5055381\ttotal: 14m 25s\tremaining: 34m 49s\n",
      "293:\tlearn: 0.5055247\ttotal: 14m 28s\tremaining: 34m 46s\n",
      "294:\tlearn: 0.5055129\ttotal: 14m 31s\tremaining: 34m 43s\n",
      "295:\tlearn: 0.5054933\ttotal: 14m 34s\tremaining: 34m 41s\n",
      "296:\tlearn: 0.5054730\ttotal: 14m 37s\tremaining: 34m 38s\n",
      "297:\tlearn: 0.5054557\ttotal: 14m 40s\tremaining: 34m 35s\n",
      "298:\tlearn: 0.5054375\ttotal: 14m 43s\tremaining: 34m 32s\n",
      "299:\tlearn: 0.5054180\ttotal: 14m 46s\tremaining: 34m 29s\n",
      "300:\tlearn: 0.5054011\ttotal: 14m 49s\tremaining: 34m 26s\n",
      "301:\tlearn: 0.5053820\ttotal: 14m 52s\tremaining: 34m 23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302:\tlearn: 0.5053520\ttotal: 14m 55s\tremaining: 34m 20s\n",
      "303:\tlearn: 0.5053218\ttotal: 14m 58s\tremaining: 34m 17s\n",
      "304:\tlearn: 0.5052947\ttotal: 15m 1s\tremaining: 34m 14s\n",
      "305:\tlearn: 0.5052729\ttotal: 15m 4s\tremaining: 34m 11s\n",
      "306:\tlearn: 0.5052537\ttotal: 15m 7s\tremaining: 34m 8s\n",
      "307:\tlearn: 0.5052324\ttotal: 15m 10s\tremaining: 34m 5s\n",
      "308:\tlearn: 0.5052146\ttotal: 15m 13s\tremaining: 34m 3s\n",
      "309:\tlearn: 0.5051960\ttotal: 15m 16s\tremaining: 34m\n",
      "310:\tlearn: 0.5051761\ttotal: 15m 19s\tremaining: 33m 57s\n",
      "311:\tlearn: 0.5051476\ttotal: 15m 22s\tremaining: 33m 54s\n",
      "312:\tlearn: 0.5051310\ttotal: 15m 25s\tremaining: 33m 51s\n",
      "313:\tlearn: 0.5051063\ttotal: 15m 28s\tremaining: 33m 48s\n",
      "314:\tlearn: 0.5050704\ttotal: 15m 31s\tremaining: 33m 45s\n",
      "315:\tlearn: 0.5050542\ttotal: 15m 34s\tremaining: 33m 42s\n",
      "316:\tlearn: 0.5050364\ttotal: 15m 37s\tremaining: 33m 39s\n",
      "317:\tlearn: 0.5050185\ttotal: 15m 40s\tremaining: 33m 36s\n",
      "318:\tlearn: 0.5050039\ttotal: 15m 43s\tremaining: 33m 33s\n",
      "319:\tlearn: 0.5049779\ttotal: 15m 46s\tremaining: 33m 30s\n",
      "320:\tlearn: 0.5049474\ttotal: 15m 49s\tremaining: 33m 27s\n",
      "321:\tlearn: 0.5049249\ttotal: 15m 52s\tremaining: 33m 24s\n",
      "322:\tlearn: 0.5049119\ttotal: 15m 55s\tremaining: 33m 21s\n",
      "323:\tlearn: 0.5048791\ttotal: 15m 58s\tremaining: 33m 18s\n",
      "324:\tlearn: 0.5048587\ttotal: 16m 1s\tremaining: 33m 16s\n",
      "325:\tlearn: 0.5048353\ttotal: 16m 3s\tremaining: 33m 13s\n",
      "326:\tlearn: 0.5048188\ttotal: 16m 6s\tremaining: 33m 9s\n",
      "327:\tlearn: 0.5048017\ttotal: 16m 9s\tremaining: 33m 6s\n",
      "328:\tlearn: 0.5047791\ttotal: 16m 12s\tremaining: 33m 3s\n",
      "329:\tlearn: 0.5047597\ttotal: 16m 15s\tremaining: 33m\n",
      "330:\tlearn: 0.5047412\ttotal: 16m 18s\tremaining: 32m 57s\n",
      "331:\tlearn: 0.5047255\ttotal: 16m 21s\tremaining: 32m 54s\n",
      "332:\tlearn: 0.5047157\ttotal: 16m 24s\tremaining: 32m 51s\n",
      "333:\tlearn: 0.5046931\ttotal: 16m 27s\tremaining: 32m 48s\n",
      "334:\tlearn: 0.5046753\ttotal: 16m 30s\tremaining: 32m 46s\n",
      "335:\tlearn: 0.5046416\ttotal: 16m 33s\tremaining: 32m 42s\n",
      "336:\tlearn: 0.5046286\ttotal: 16m 36s\tremaining: 32m 39s\n",
      "337:\tlearn: 0.5046132\ttotal: 16m 39s\tremaining: 32m 36s\n",
      "338:\tlearn: 0.5045911\ttotal: 16m 42s\tremaining: 32m 33s\n",
      "339:\tlearn: 0.5045724\ttotal: 16m 45s\tremaining: 32m 30s\n",
      "340:\tlearn: 0.5045627\ttotal: 16m 47s\tremaining: 32m 28s\n",
      "341:\tlearn: 0.5045353\ttotal: 16m 50s\tremaining: 32m 24s\n",
      "342:\tlearn: 0.5045196\ttotal: 16m 53s\tremaining: 32m 22s\n",
      "343:\tlearn: 0.5044961\ttotal: 16m 56s\tremaining: 32m 18s\n",
      "344:\tlearn: 0.5044793\ttotal: 16m 59s\tremaining: 32m 15s\n",
      "345:\tlearn: 0.5044563\ttotal: 17m 2s\tremaining: 32m 12s\n",
      "346:\tlearn: 0.5044347\ttotal: 17m 5s\tremaining: 32m 9s\n",
      "347:\tlearn: 0.5044205\ttotal: 17m 8s\tremaining: 32m 6s\n",
      "348:\tlearn: 0.5044000\ttotal: 17m 11s\tremaining: 32m 4s\n",
      "349:\tlearn: 0.5043751\ttotal: 17m 14s\tremaining: 32m 1s\n",
      "350:\tlearn: 0.5043530\ttotal: 17m 17s\tremaining: 31m 58s\n",
      "351:\tlearn: 0.5043398\ttotal: 17m 20s\tremaining: 31m 55s\n",
      "352:\tlearn: 0.5043149\ttotal: 17m 23s\tremaining: 31m 52s\n",
      "353:\tlearn: 0.5043031\ttotal: 17m 26s\tremaining: 31m 49s\n",
      "354:\tlearn: 0.5042853\ttotal: 17m 29s\tremaining: 31m 46s\n",
      "355:\tlearn: 0.5042688\ttotal: 17m 32s\tremaining: 31m 43s\n",
      "356:\tlearn: 0.5042551\ttotal: 17m 35s\tremaining: 31m 40s\n",
      "357:\tlearn: 0.5042435\ttotal: 17m 37s\tremaining: 31m 37s\n",
      "358:\tlearn: 0.5042292\ttotal: 17m 40s\tremaining: 31m 34s\n",
      "359:\tlearn: 0.5042123\ttotal: 17m 43s\tremaining: 31m 31s\n",
      "360:\tlearn: 0.5041837\ttotal: 17m 46s\tremaining: 31m 28s\n",
      "361:\tlearn: 0.5041758\ttotal: 17m 49s\tremaining: 31m 25s\n",
      "362:\tlearn: 0.5041503\ttotal: 17m 52s\tremaining: 31m 22s\n",
      "363:\tlearn: 0.5041349\ttotal: 17m 55s\tremaining: 31m 19s\n",
      "364:\tlearn: 0.5041158\ttotal: 17m 58s\tremaining: 31m 16s\n",
      "365:\tlearn: 0.5041037\ttotal: 18m 1s\tremaining: 31m 13s\n",
      "366:\tlearn: 0.5040861\ttotal: 18m 4s\tremaining: 31m 10s\n",
      "367:\tlearn: 0.5040695\ttotal: 18m 7s\tremaining: 31m 7s\n",
      "368:\tlearn: 0.5040487\ttotal: 18m 10s\tremaining: 31m 4s\n",
      "369:\tlearn: 0.5040319\ttotal: 18m 13s\tremaining: 31m 1s\n",
      "370:\tlearn: 0.5040107\ttotal: 18m 16s\tremaining: 30m 58s\n",
      "371:\tlearn: 0.5039937\ttotal: 18m 19s\tremaining: 30m 55s\n",
      "372:\tlearn: 0.5039691\ttotal: 18m 22s\tremaining: 30m 52s\n",
      "373:\tlearn: 0.5039434\ttotal: 18m 25s\tremaining: 30m 49s\n",
      "374:\tlearn: 0.5039298\ttotal: 18m 28s\tremaining: 30m 46s\n",
      "375:\tlearn: 0.5039183\ttotal: 18m 31s\tremaining: 30m 43s\n",
      "376:\tlearn: 0.5039032\ttotal: 18m 34s\tremaining: 30m 41s\n",
      "377:\tlearn: 0.5038826\ttotal: 18m 36s\tremaining: 30m 37s\n",
      "378:\tlearn: 0.5038656\ttotal: 18m 39s\tremaining: 30m 34s\n",
      "379:\tlearn: 0.5038439\ttotal: 18m 42s\tremaining: 30m 31s\n",
      "380:\tlearn: 0.5038116\ttotal: 18m 45s\tremaining: 30m 28s\n",
      "381:\tlearn: 0.5037908\ttotal: 18m 48s\tremaining: 30m 26s\n",
      "382:\tlearn: 0.5037805\ttotal: 18m 51s\tremaining: 30m 23s\n",
      "383:\tlearn: 0.5037622\ttotal: 18m 54s\tremaining: 30m 20s\n",
      "384:\tlearn: 0.5037469\ttotal: 18m 57s\tremaining: 30m 17s\n",
      "385:\tlearn: 0.5037274\ttotal: 19m\tremaining: 30m 14s\n",
      "386:\tlearn: 0.5037125\ttotal: 19m 3s\tremaining: 30m 11s\n",
      "387:\tlearn: 0.5036925\ttotal: 19m 6s\tremaining: 30m 8s\n",
      "388:\tlearn: 0.5036782\ttotal: 19m 9s\tremaining: 30m 5s\n",
      "389:\tlearn: 0.5036649\ttotal: 19m 12s\tremaining: 30m 2s\n",
      "390:\tlearn: 0.5036520\ttotal: 19m 15s\tremaining: 29m 59s\n",
      "391:\tlearn: 0.5036305\ttotal: 19m 18s\tremaining: 29m 56s\n",
      "392:\tlearn: 0.5036236\ttotal: 19m 21s\tremaining: 29m 53s\n",
      "393:\tlearn: 0.5035956\ttotal: 19m 24s\tremaining: 29m 50s\n",
      "394:\tlearn: 0.5035761\ttotal: 19m 27s\tremaining: 29m 47s\n",
      "395:\tlearn: 0.5035598\ttotal: 19m 30s\tremaining: 29m 44s\n",
      "396:\tlearn: 0.5035438\ttotal: 19m 33s\tremaining: 29m 41s\n",
      "397:\tlearn: 0.5035232\ttotal: 19m 36s\tremaining: 29m 39s\n",
      "398:\tlearn: 0.5035036\ttotal: 19m 39s\tremaining: 29m 36s\n",
      "399:\tlearn: 0.5034857\ttotal: 19m 42s\tremaining: 29m 33s\n",
      "400:\tlearn: 0.5034646\ttotal: 19m 45s\tremaining: 29m 30s\n",
      "401:\tlearn: 0.5034380\ttotal: 19m 47s\tremaining: 29m 27s\n",
      "402:\tlearn: 0.5034113\ttotal: 19m 50s\tremaining: 29m 24s\n",
      "403:\tlearn: 0.5033915\ttotal: 19m 53s\tremaining: 29m 21s\n",
      "404:\tlearn: 0.5033714\ttotal: 19m 56s\tremaining: 29m 18s\n",
      "405:\tlearn: 0.5033579\ttotal: 19m 59s\tremaining: 29m 15s\n",
      "406:\tlearn: 0.5033490\ttotal: 20m 2s\tremaining: 29m 12s\n",
      "407:\tlearn: 0.5033375\ttotal: 20m 5s\tremaining: 29m 9s\n",
      "408:\tlearn: 0.5033163\ttotal: 20m 8s\tremaining: 29m 6s\n",
      "409:\tlearn: 0.5033031\ttotal: 20m 11s\tremaining: 29m 3s\n",
      "410:\tlearn: 0.5032879\ttotal: 20m 14s\tremaining: 29m\n",
      "411:\tlearn: 0.5032694\ttotal: 20m 17s\tremaining: 28m 57s\n",
      "412:\tlearn: 0.5032508\ttotal: 20m 20s\tremaining: 28m 54s\n",
      "413:\tlearn: 0.5032321\ttotal: 20m 23s\tremaining: 28m 51s\n",
      "414:\tlearn: 0.5032113\ttotal: 20m 26s\tremaining: 28m 48s\n",
      "415:\tlearn: 0.5031915\ttotal: 20m 29s\tremaining: 28m 45s\n",
      "416:\tlearn: 0.5031715\ttotal: 20m 32s\tremaining: 28m 42s\n",
      "417:\tlearn: 0.5031585\ttotal: 20m 35s\tremaining: 28m 39s\n",
      "418:\tlearn: 0.5031457\ttotal: 20m 38s\tremaining: 28m 36s\n",
      "419:\tlearn: 0.5031313\ttotal: 20m 41s\tremaining: 28m 33s\n",
      "420:\tlearn: 0.5031235\ttotal: 20m 44s\tremaining: 28m 30s\n",
      "421:\tlearn: 0.5031078\ttotal: 20m 47s\tremaining: 28m 28s\n",
      "422:\tlearn: 0.5030904\ttotal: 20m 49s\tremaining: 28m 25s\n",
      "423:\tlearn: 0.5030752\ttotal: 20m 52s\tremaining: 28m 22s\n",
      "424:\tlearn: 0.5030627\ttotal: 20m 55s\tremaining: 28m 19s\n",
      "425:\tlearn: 0.5030414\ttotal: 20m 58s\tremaining: 28m 16s\n",
      "426:\tlearn: 0.5030245\ttotal: 21m 1s\tremaining: 28m 13s\n",
      "427:\tlearn: 0.5030062\ttotal: 21m 4s\tremaining: 28m 10s\n",
      "428:\tlearn: 0.5029941\ttotal: 21m 7s\tremaining: 28m 7s\n",
      "429:\tlearn: 0.5029822\ttotal: 21m 10s\tremaining: 28m 4s\n",
      "430:\tlearn: 0.5029667\ttotal: 21m 13s\tremaining: 28m 1s\n",
      "431:\tlearn: 0.5029573\ttotal: 21m 16s\tremaining: 27m 58s\n",
      "432:\tlearn: 0.5029224\ttotal: 21m 19s\tremaining: 27m 55s\n",
      "433:\tlearn: 0.5029063\ttotal: 21m 22s\tremaining: 27m 52s\n",
      "434:\tlearn: 0.5028910\ttotal: 21m 25s\tremaining: 27m 49s\n",
      "435:\tlearn: 0.5028742\ttotal: 21m 28s\tremaining: 27m 46s\n",
      "436:\tlearn: 0.5028642\ttotal: 21m 31s\tremaining: 27m 43s\n",
      "437:\tlearn: 0.5028469\ttotal: 21m 34s\tremaining: 27m 40s\n",
      "438:\tlearn: 0.5028355\ttotal: 21m 37s\tremaining: 27m 37s\n",
      "439:\tlearn: 0.5028154\ttotal: 21m 40s\tremaining: 27m 34s\n",
      "440:\tlearn: 0.5027922\ttotal: 21m 43s\tremaining: 27m 31s\n",
      "441:\tlearn: 0.5027747\ttotal: 21m 46s\tremaining: 27m 29s\n",
      "442:\tlearn: 0.5027558\ttotal: 21m 49s\tremaining: 27m 26s\n",
      "443:\tlearn: 0.5027349\ttotal: 21m 52s\tremaining: 27m 23s\n",
      "444:\tlearn: 0.5027160\ttotal: 21m 55s\tremaining: 27m 20s\n",
      "445:\tlearn: 0.5027031\ttotal: 21m 58s\tremaining: 27m 17s\n",
      "446:\tlearn: 0.5026865\ttotal: 22m 1s\tremaining: 27m 14s\n",
      "447:\tlearn: 0.5026744\ttotal: 22m 3s\tremaining: 27m 11s\n",
      "448:\tlearn: 0.5026565\ttotal: 22m 6s\tremaining: 27m 8s\n",
      "449:\tlearn: 0.5026455\ttotal: 22m 9s\tremaining: 27m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450:\tlearn: 0.5026322\ttotal: 22m 12s\tremaining: 27m 2s\n",
      "451:\tlearn: 0.5026154\ttotal: 22m 15s\tremaining: 26m 59s\n",
      "452:\tlearn: 0.5025962\ttotal: 22m 18s\tremaining: 26m 56s\n",
      "453:\tlearn: 0.5025857\ttotal: 22m 21s\tremaining: 26m 53s\n",
      "454:\tlearn: 0.5025726\ttotal: 22m 24s\tremaining: 26m 50s\n",
      "455:\tlearn: 0.5025618\ttotal: 22m 27s\tremaining: 26m 47s\n",
      "456:\tlearn: 0.5025501\ttotal: 22m 30s\tremaining: 26m 44s\n",
      "457:\tlearn: 0.5025402\ttotal: 22m 33s\tremaining: 26m 42s\n",
      "458:\tlearn: 0.5025227\ttotal: 22m 36s\tremaining: 26m 39s\n",
      "459:\tlearn: 0.5025045\ttotal: 22m 39s\tremaining: 26m 36s\n",
      "460:\tlearn: 0.5024849\ttotal: 22m 42s\tremaining: 26m 33s\n",
      "461:\tlearn: 0.5024724\ttotal: 22m 45s\tremaining: 26m 30s\n",
      "462:\tlearn: 0.5024543\ttotal: 22m 48s\tremaining: 26m 27s\n",
      "463:\tlearn: 0.5024464\ttotal: 22m 51s\tremaining: 26m 24s\n",
      "464:\tlearn: 0.5024219\ttotal: 22m 54s\tremaining: 26m 21s\n",
      "465:\tlearn: 0.5024066\ttotal: 22m 57s\tremaining: 26m 18s\n",
      "466:\tlearn: 0.5023907\ttotal: 23m\tremaining: 26m 15s\n",
      "467:\tlearn: 0.5023711\ttotal: 23m 3s\tremaining: 26m 12s\n",
      "468:\tlearn: 0.5023541\ttotal: 23m 6s\tremaining: 26m 9s\n",
      "469:\tlearn: 0.5023305\ttotal: 23m 9s\tremaining: 26m 6s\n",
      "470:\tlearn: 0.5023158\ttotal: 23m 12s\tremaining: 26m 3s\n",
      "471:\tlearn: 0.5023016\ttotal: 23m 15s\tremaining: 26m\n",
      "472:\tlearn: 0.5022906\ttotal: 23m 18s\tremaining: 25m 58s\n",
      "473:\tlearn: 0.5022803\ttotal: 23m 21s\tremaining: 25m 55s\n",
      "474:\tlearn: 0.5022633\ttotal: 23m 24s\tremaining: 25m 52s\n",
      "475:\tlearn: 0.5022494\ttotal: 23m 27s\tremaining: 25m 49s\n",
      "476:\tlearn: 0.5022339\ttotal: 23m 30s\tremaining: 25m 46s\n",
      "477:\tlearn: 0.5022175\ttotal: 23m 33s\tremaining: 25m 43s\n",
      "478:\tlearn: 0.5022034\ttotal: 23m 36s\tremaining: 25m 40s\n",
      "479:\tlearn: 0.5021898\ttotal: 23m 39s\tremaining: 25m 37s\n",
      "480:\tlearn: 0.5021814\ttotal: 23m 42s\tremaining: 25m 34s\n",
      "481:\tlearn: 0.5021660\ttotal: 23m 45s\tremaining: 25m 31s\n",
      "482:\tlearn: 0.5021491\ttotal: 23m 48s\tremaining: 25m 28s\n",
      "483:\tlearn: 0.5021323\ttotal: 23m 51s\tremaining: 25m 26s\n",
      "484:\tlearn: 0.5021183\ttotal: 23m 54s\tremaining: 25m 23s\n",
      "485:\tlearn: 0.5021063\ttotal: 23m 57s\tremaining: 25m 20s\n",
      "486:\tlearn: 0.5020930\ttotal: 24m\tremaining: 25m 17s\n",
      "487:\tlearn: 0.5020811\ttotal: 24m 3s\tremaining: 25m 14s\n",
      "488:\tlearn: 0.5020669\ttotal: 24m 6s\tremaining: 25m 11s\n",
      "489:\tlearn: 0.5020521\ttotal: 24m 9s\tremaining: 25m 8s\n",
      "490:\tlearn: 0.5020408\ttotal: 24m 12s\tremaining: 25m 5s\n",
      "491:\tlearn: 0.5020280\ttotal: 24m 15s\tremaining: 25m 2s\n",
      "492:\tlearn: 0.5020093\ttotal: 24m 18s\tremaining: 24m 59s\n",
      "493:\tlearn: 0.5019902\ttotal: 24m 21s\tremaining: 24m 56s\n",
      "494:\tlearn: 0.5019776\ttotal: 24m 24s\tremaining: 24m 53s\n",
      "495:\tlearn: 0.5019671\ttotal: 24m 27s\tremaining: 24m 50s\n",
      "496:\tlearn: 0.5019507\ttotal: 24m 30s\tremaining: 24m 47s\n",
      "497:\tlearn: 0.5019385\ttotal: 24m 33s\tremaining: 24m 44s\n",
      "498:\tlearn: 0.5019206\ttotal: 24m 36s\tremaining: 24m 41s\n",
      "499:\tlearn: 0.5019077\ttotal: 24m 38s\tremaining: 24m 38s\n",
      "500:\tlearn: 0.5018909\ttotal: 24m 41s\tremaining: 24m 35s\n",
      "501:\tlearn: 0.5018744\ttotal: 24m 44s\tremaining: 24m 33s\n",
      "502:\tlearn: 0.5018543\ttotal: 24m 47s\tremaining: 24m 30s\n",
      "503:\tlearn: 0.5018433\ttotal: 24m 50s\tremaining: 24m 27s\n",
      "504:\tlearn: 0.5018276\ttotal: 24m 53s\tremaining: 24m 24s\n",
      "505:\tlearn: 0.5018150\ttotal: 24m 56s\tremaining: 24m 21s\n",
      "506:\tlearn: 0.5017905\ttotal: 24m 59s\tremaining: 24m 18s\n",
      "507:\tlearn: 0.5017729\ttotal: 25m 2s\tremaining: 24m 15s\n",
      "508:\tlearn: 0.5017543\ttotal: 25m 5s\tremaining: 24m 12s\n",
      "509:\tlearn: 0.5017427\ttotal: 25m 8s\tremaining: 24m 9s\n",
      "510:\tlearn: 0.5017325\ttotal: 25m 11s\tremaining: 24m 6s\n",
      "511:\tlearn: 0.5017206\ttotal: 25m 14s\tremaining: 24m 3s\n",
      "512:\tlearn: 0.5017051\ttotal: 25m 17s\tremaining: 24m\n",
      "513:\tlearn: 0.5016940\ttotal: 25m 20s\tremaining: 23m 57s\n",
      "514:\tlearn: 0.5016838\ttotal: 25m 23s\tremaining: 23m 54s\n",
      "515:\tlearn: 0.5016653\ttotal: 25m 26s\tremaining: 23m 51s\n",
      "516:\tlearn: 0.5016571\ttotal: 25m 29s\tremaining: 23m 48s\n",
      "517:\tlearn: 0.5016423\ttotal: 25m 32s\tremaining: 23m 45s\n",
      "518:\tlearn: 0.5016272\ttotal: 25m 35s\tremaining: 23m 42s\n",
      "519:\tlearn: 0.5016109\ttotal: 25m 38s\tremaining: 23m 39s\n",
      "520:\tlearn: 0.5016055\ttotal: 25m 41s\tremaining: 23m 37s\n",
      "521:\tlearn: 0.5015919\ttotal: 25m 44s\tremaining: 23m 34s\n",
      "522:\tlearn: 0.5015764\ttotal: 25m 47s\tremaining: 23m 31s\n",
      "523:\tlearn: 0.5015620\ttotal: 25m 50s\tremaining: 23m 28s\n",
      "524:\tlearn: 0.5015480\ttotal: 25m 52s\tremaining: 23m 25s\n",
      "525:\tlearn: 0.5015357\ttotal: 25m 55s\tremaining: 23m 22s\n",
      "526:\tlearn: 0.5015125\ttotal: 25m 58s\tremaining: 23m 19s\n",
      "527:\tlearn: 0.5014910\ttotal: 26m 1s\tremaining: 23m 16s\n",
      "528:\tlearn: 0.5014782\ttotal: 26m 4s\tremaining: 23m 13s\n",
      "529:\tlearn: 0.5014595\ttotal: 26m 7s\tremaining: 23m 10s\n",
      "530:\tlearn: 0.5014517\ttotal: 26m 10s\tremaining: 23m 7s\n",
      "531:\tlearn: 0.5014374\ttotal: 26m 13s\tremaining: 23m 4s\n",
      "532:\tlearn: 0.5014238\ttotal: 26m 16s\tremaining: 23m 1s\n",
      "533:\tlearn: 0.5014146\ttotal: 26m 19s\tremaining: 22m 58s\n",
      "534:\tlearn: 0.5013982\ttotal: 26m 22s\tremaining: 22m 55s\n",
      "535:\tlearn: 0.5013883\ttotal: 26m 25s\tremaining: 22m 52s\n",
      "536:\tlearn: 0.5013777\ttotal: 26m 28s\tremaining: 22m 49s\n",
      "537:\tlearn: 0.5013656\ttotal: 26m 31s\tremaining: 22m 46s\n",
      "538:\tlearn: 0.5013587\ttotal: 26m 34s\tremaining: 22m 43s\n",
      "539:\tlearn: 0.5013407\ttotal: 26m 37s\tremaining: 22m 40s\n",
      "540:\tlearn: 0.5013294\ttotal: 26m 40s\tremaining: 22m 37s\n",
      "541:\tlearn: 0.5013132\ttotal: 26m 43s\tremaining: 22m 35s\n",
      "542:\tlearn: 0.5012973\ttotal: 26m 46s\tremaining: 22m 31s\n",
      "543:\tlearn: 0.5012790\ttotal: 26m 49s\tremaining: 22m 29s\n",
      "544:\tlearn: 0.5012621\ttotal: 26m 52s\tremaining: 22m 26s\n",
      "545:\tlearn: 0.5012538\ttotal: 26m 55s\tremaining: 22m 23s\n",
      "546:\tlearn: 0.5012384\ttotal: 26m 58s\tremaining: 22m 20s\n",
      "547:\tlearn: 0.5012258\ttotal: 27m 1s\tremaining: 22m 17s\n",
      "548:\tlearn: 0.5012086\ttotal: 27m 4s\tremaining: 22m 14s\n",
      "549:\tlearn: 0.5011918\ttotal: 27m 7s\tremaining: 22m 11s\n",
      "550:\tlearn: 0.5011746\ttotal: 27m 10s\tremaining: 22m 8s\n",
      "551:\tlearn: 0.5011623\ttotal: 27m 13s\tremaining: 22m 5s\n",
      "552:\tlearn: 0.5011455\ttotal: 27m 16s\tremaining: 22m 2s\n",
      "553:\tlearn: 0.5011313\ttotal: 27m 19s\tremaining: 21m 59s\n",
      "554:\tlearn: 0.5011176\ttotal: 27m 21s\tremaining: 21m 56s\n",
      "555:\tlearn: 0.5011054\ttotal: 27m 24s\tremaining: 21m 53s\n",
      "556:\tlearn: 0.5010846\ttotal: 27m 27s\tremaining: 21m 50s\n",
      "557:\tlearn: 0.5010622\ttotal: 27m 30s\tremaining: 21m 47s\n",
      "558:\tlearn: 0.5010479\ttotal: 27m 33s\tremaining: 21m 44s\n",
      "559:\tlearn: 0.5010393\ttotal: 27m 36s\tremaining: 21m 41s\n",
      "560:\tlearn: 0.5010270\ttotal: 27m 39s\tremaining: 21m 38s\n",
      "561:\tlearn: 0.5010049\ttotal: 27m 42s\tremaining: 21m 35s\n",
      "562:\tlearn: 0.5009918\ttotal: 27m 45s\tremaining: 21m 32s\n",
      "563:\tlearn: 0.5009805\ttotal: 27m 48s\tremaining: 21m 30s\n",
      "564:\tlearn: 0.5009658\ttotal: 27m 51s\tremaining: 21m 27s\n",
      "565:\tlearn: 0.5009470\ttotal: 27m 54s\tremaining: 21m 24s\n",
      "566:\tlearn: 0.5009397\ttotal: 27m 57s\tremaining: 21m 21s\n",
      "567:\tlearn: 0.5009298\ttotal: 28m\tremaining: 21m 18s\n",
      "568:\tlearn: 0.5009096\ttotal: 28m 3s\tremaining: 21m 15s\n",
      "569:\tlearn: 0.5008979\ttotal: 28m 6s\tremaining: 21m 12s\n",
      "570:\tlearn: 0.5008774\ttotal: 28m 9s\tremaining: 21m 9s\n",
      "571:\tlearn: 0.5008616\ttotal: 28m 12s\tremaining: 21m 6s\n",
      "572:\tlearn: 0.5008504\ttotal: 28m 15s\tremaining: 21m 3s\n",
      "573:\tlearn: 0.5008344\ttotal: 28m 18s\tremaining: 21m\n",
      "574:\tlearn: 0.5008209\ttotal: 28m 21s\tremaining: 20m 57s\n",
      "575:\tlearn: 0.5008063\ttotal: 28m 24s\tremaining: 20m 54s\n",
      "576:\tlearn: 0.5007897\ttotal: 28m 27s\tremaining: 20m 51s\n",
      "577:\tlearn: 0.5007767\ttotal: 28m 30s\tremaining: 20m 48s\n",
      "578:\tlearn: 0.5007654\ttotal: 28m 32s\tremaining: 20m 45s\n",
      "579:\tlearn: 0.5007498\ttotal: 28m 35s\tremaining: 20m 42s\n",
      "580:\tlearn: 0.5007370\ttotal: 28m 38s\tremaining: 20m 39s\n",
      "581:\tlearn: 0.5007263\ttotal: 28m 41s\tremaining: 20m 36s\n",
      "582:\tlearn: 0.5007108\ttotal: 28m 44s\tremaining: 20m 33s\n",
      "583:\tlearn: 0.5007012\ttotal: 28m 47s\tremaining: 20m 30s\n",
      "584:\tlearn: 0.5006867\ttotal: 28m 50s\tremaining: 20m 27s\n",
      "585:\tlearn: 0.5006742\ttotal: 28m 53s\tremaining: 20m 24s\n",
      "586:\tlearn: 0.5006590\ttotal: 28m 56s\tremaining: 20m 21s\n",
      "587:\tlearn: 0.5006369\ttotal: 28m 59s\tremaining: 20m 18s\n",
      "588:\tlearn: 0.5006233\ttotal: 29m 2s\tremaining: 20m 15s\n",
      "589:\tlearn: 0.5006110\ttotal: 29m 5s\tremaining: 20m 12s\n",
      "590:\tlearn: 0.5005951\ttotal: 29m 8s\tremaining: 20m 9s\n",
      "591:\tlearn: 0.5005796\ttotal: 29m 11s\tremaining: 20m 6s\n",
      "592:\tlearn: 0.5005681\ttotal: 29m 13s\tremaining: 20m 3s\n",
      "593:\tlearn: 0.5005551\ttotal: 29m 17s\tremaining: 20m\n",
      "594:\tlearn: 0.5005432\ttotal: 29m 20s\tremaining: 19m 57s\n",
      "595:\tlearn: 0.5005243\ttotal: 29m 22s\tremaining: 19m 55s\n",
      "596:\tlearn: 0.5005163\ttotal: 29m 25s\tremaining: 19m 52s\n",
      "597:\tlearn: 0.5005042\ttotal: 29m 28s\tremaining: 19m 49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598:\tlearn: 0.5004882\ttotal: 29m 31s\tremaining: 19m 46s\n",
      "599:\tlearn: 0.5004778\ttotal: 29m 34s\tremaining: 19m 43s\n",
      "600:\tlearn: 0.5004624\ttotal: 29m 37s\tremaining: 19m 40s\n",
      "601:\tlearn: 0.5004462\ttotal: 29m 40s\tremaining: 19m 37s\n",
      "602:\tlearn: 0.5004262\ttotal: 29m 43s\tremaining: 19m 34s\n",
      "603:\tlearn: 0.5004131\ttotal: 29m 46s\tremaining: 19m 31s\n",
      "604:\tlearn: 0.5003973\ttotal: 29m 49s\tremaining: 19m 28s\n",
      "605:\tlearn: 0.5003826\ttotal: 29m 52s\tremaining: 19m 25s\n",
      "606:\tlearn: 0.5003596\ttotal: 29m 55s\tremaining: 19m 22s\n",
      "607:\tlearn: 0.5003419\ttotal: 29m 58s\tremaining: 19m 19s\n",
      "608:\tlearn: 0.5003197\ttotal: 30m 1s\tremaining: 19m 16s\n",
      "609:\tlearn: 0.5003152\ttotal: 30m 4s\tremaining: 19m 13s\n",
      "610:\tlearn: 0.5003044\ttotal: 30m 7s\tremaining: 19m 10s\n",
      "611:\tlearn: 0.5002941\ttotal: 30m 10s\tremaining: 19m 7s\n",
      "612:\tlearn: 0.5002884\ttotal: 30m 13s\tremaining: 19m 4s\n",
      "613:\tlearn: 0.5002773\ttotal: 30m 16s\tremaining: 19m 1s\n",
      "614:\tlearn: 0.5002609\ttotal: 30m 19s\tremaining: 18m 58s\n",
      "615:\tlearn: 0.5002501\ttotal: 30m 22s\tremaining: 18m 55s\n",
      "616:\tlearn: 0.5002302\ttotal: 30m 25s\tremaining: 18m 52s\n",
      "617:\tlearn: 0.5002137\ttotal: 30m 28s\tremaining: 18m 50s\n",
      "618:\tlearn: 0.5002043\ttotal: 30m 31s\tremaining: 18m 47s\n",
      "619:\tlearn: 0.5001887\ttotal: 30m 34s\tremaining: 18m 44s\n",
      "620:\tlearn: 0.5001779\ttotal: 30m 37s\tremaining: 18m 41s\n",
      "621:\tlearn: 0.5001642\ttotal: 30m 40s\tremaining: 18m 38s\n",
      "622:\tlearn: 0.5001557\ttotal: 30m 43s\tremaining: 18m 35s\n",
      "623:\tlearn: 0.5001492\ttotal: 30m 46s\tremaining: 18m 32s\n",
      "624:\tlearn: 0.5001283\ttotal: 30m 48s\tremaining: 18m 29s\n",
      "625:\tlearn: 0.5001157\ttotal: 30m 51s\tremaining: 18m 26s\n",
      "626:\tlearn: 0.5000976\ttotal: 30m 54s\tremaining: 18m 23s\n",
      "627:\tlearn: 0.5000920\ttotal: 30m 58s\tremaining: 18m 20s\n",
      "628:\tlearn: 0.5000793\ttotal: 31m\tremaining: 18m 17s\n",
      "629:\tlearn: 0.5000649\ttotal: 31m 4s\tremaining: 18m 14s\n",
      "630:\tlearn: 0.5000585\ttotal: 31m 7s\tremaining: 18m 11s\n",
      "631:\tlearn: 0.5000494\ttotal: 31m 10s\tremaining: 18m 8s\n",
      "632:\tlearn: 0.5000339\ttotal: 31m 12s\tremaining: 18m 5s\n",
      "633:\tlearn: 0.5000235\ttotal: 31m 15s\tremaining: 18m 2s\n",
      "634:\tlearn: 0.5000138\ttotal: 31m 18s\tremaining: 18m\n",
      "635:\tlearn: 0.5000083\ttotal: 31m 21s\tremaining: 17m 57s\n",
      "636:\tlearn: 0.4999974\ttotal: 31m 24s\tremaining: 17m 54s\n",
      "637:\tlearn: 0.4999819\ttotal: 31m 27s\tremaining: 17m 51s\n",
      "638:\tlearn: 0.4999670\ttotal: 31m 30s\tremaining: 17m 48s\n",
      "639:\tlearn: 0.4999508\ttotal: 31m 33s\tremaining: 17m 45s\n",
      "640:\tlearn: 0.4999367\ttotal: 31m 36s\tremaining: 17m 42s\n",
      "641:\tlearn: 0.4999253\ttotal: 31m 39s\tremaining: 17m 39s\n",
      "642:\tlearn: 0.4999121\ttotal: 31m 42s\tremaining: 17m 36s\n",
      "643:\tlearn: 0.4998983\ttotal: 31m 45s\tremaining: 17m 33s\n",
      "644:\tlearn: 0.4998860\ttotal: 31m 48s\tremaining: 17m 30s\n",
      "645:\tlearn: 0.4998753\ttotal: 31m 51s\tremaining: 17m 27s\n",
      "646:\tlearn: 0.4998617\ttotal: 31m 54s\tremaining: 17m 24s\n",
      "647:\tlearn: 0.4998449\ttotal: 31m 57s\tremaining: 17m 21s\n",
      "648:\tlearn: 0.4998340\ttotal: 32m\tremaining: 17m 18s\n",
      "649:\tlearn: 0.4998199\ttotal: 32m 3s\tremaining: 17m 15s\n",
      "650:\tlearn: 0.4998093\ttotal: 32m 6s\tremaining: 17m 12s\n",
      "651:\tlearn: 0.4997988\ttotal: 32m 9s\tremaining: 17m 9s\n",
      "652:\tlearn: 0.4997853\ttotal: 32m 12s\tremaining: 17m 7s\n",
      "653:\tlearn: 0.4997736\ttotal: 32m 15s\tremaining: 17m 4s\n",
      "654:\tlearn: 0.4997560\ttotal: 32m 18s\tremaining: 17m 1s\n",
      "655:\tlearn: 0.4997357\ttotal: 32m 21s\tremaining: 16m 58s\n",
      "656:\tlearn: 0.4997211\ttotal: 32m 24s\tremaining: 16m 55s\n",
      "657:\tlearn: 0.4997068\ttotal: 32m 27s\tremaining: 16m 52s\n",
      "658:\tlearn: 0.4996986\ttotal: 32m 30s\tremaining: 16m 49s\n",
      "659:\tlearn: 0.4996936\ttotal: 32m 33s\tremaining: 16m 46s\n",
      "660:\tlearn: 0.4996797\ttotal: 32m 36s\tremaining: 16m 43s\n",
      "661:\tlearn: 0.4996669\ttotal: 32m 39s\tremaining: 16m 40s\n",
      "662:\tlearn: 0.4996546\ttotal: 32m 42s\tremaining: 16m 37s\n",
      "663:\tlearn: 0.4996424\ttotal: 32m 45s\tremaining: 16m 34s\n",
      "664:\tlearn: 0.4996249\ttotal: 32m 48s\tremaining: 16m 31s\n",
      "665:\tlearn: 0.4996125\ttotal: 32m 50s\tremaining: 16m 28s\n",
      "666:\tlearn: 0.4996005\ttotal: 32m 53s\tremaining: 16m 25s\n",
      "667:\tlearn: 0.4995894\ttotal: 32m 56s\tremaining: 16m 22s\n",
      "668:\tlearn: 0.4995716\ttotal: 32m 59s\tremaining: 16m 19s\n",
      "669:\tlearn: 0.4995493\ttotal: 33m 2s\tremaining: 16m 16s\n",
      "670:\tlearn: 0.4995351\ttotal: 33m 5s\tremaining: 16m 13s\n",
      "671:\tlearn: 0.4995190\ttotal: 33m 8s\tremaining: 16m 10s\n",
      "672:\tlearn: 0.4995032\ttotal: 33m 11s\tremaining: 16m 7s\n",
      "673:\tlearn: 0.4994936\ttotal: 33m 13s\tremaining: 16m 4s\n",
      "674:\tlearn: 0.4994790\ttotal: 33m 16s\tremaining: 16m 1s\n",
      "675:\tlearn: 0.4994628\ttotal: 33m 19s\tremaining: 15m 58s\n",
      "676:\tlearn: 0.4994456\ttotal: 33m 22s\tremaining: 15m 55s\n",
      "677:\tlearn: 0.4994298\ttotal: 33m 25s\tremaining: 15m 52s\n",
      "678:\tlearn: 0.4994095\ttotal: 33m 27s\tremaining: 15m 49s\n",
      "679:\tlearn: 0.4993968\ttotal: 33m 30s\tremaining: 15m 46s\n",
      "680:\tlearn: 0.4993803\ttotal: 33m 33s\tremaining: 15m 43s\n",
      "681:\tlearn: 0.4993634\ttotal: 33m 36s\tremaining: 15m 40s\n",
      "682:\tlearn: 0.4993480\ttotal: 33m 38s\tremaining: 15m 36s\n",
      "683:\tlearn: 0.4993371\ttotal: 33m 41s\tremaining: 15m 34s\n",
      "684:\tlearn: 0.4993226\ttotal: 33m 44s\tremaining: 15m 31s\n",
      "685:\tlearn: 0.4993103\ttotal: 33m 47s\tremaining: 15m 27s\n",
      "686:\tlearn: 0.4992946\ttotal: 33m 50s\tremaining: 15m 24s\n",
      "687:\tlearn: 0.4992813\ttotal: 33m 52s\tremaining: 15m 21s\n",
      "688:\tlearn: 0.4992660\ttotal: 33m 55s\tremaining: 15m 18s\n",
      "689:\tlearn: 0.4992498\ttotal: 33m 58s\tremaining: 15m 15s\n",
      "690:\tlearn: 0.4992353\ttotal: 34m 1s\tremaining: 15m 12s\n",
      "691:\tlearn: 0.4992166\ttotal: 34m 4s\tremaining: 15m 9s\n",
      "692:\tlearn: 0.4991999\ttotal: 34m 7s\tremaining: 15m 6s\n",
      "693:\tlearn: 0.4991903\ttotal: 34m 9s\tremaining: 15m 3s\n",
      "694:\tlearn: 0.4991803\ttotal: 34m 12s\tremaining: 15m\n",
      "695:\tlearn: 0.4991672\ttotal: 34m 15s\tremaining: 14m 57s\n",
      "696:\tlearn: 0.4991582\ttotal: 34m 18s\tremaining: 14m 54s\n",
      "697:\tlearn: 0.4991447\ttotal: 34m 20s\tremaining: 14m 51s\n",
      "698:\tlearn: 0.4991329\ttotal: 34m 23s\tremaining: 14m 48s\n",
      "699:\tlearn: 0.4991246\ttotal: 34m 26s\tremaining: 14m 45s\n",
      "700:\tlearn: 0.4991093\ttotal: 34m 29s\tremaining: 14m 42s\n",
      "701:\tlearn: 0.4990942\ttotal: 34m 31s\tremaining: 14m 39s\n",
      "702:\tlearn: 0.4990817\ttotal: 34m 34s\tremaining: 14m 36s\n",
      "703:\tlearn: 0.4990578\ttotal: 34m 37s\tremaining: 14m 33s\n",
      "704:\tlearn: 0.4990335\ttotal: 34m 40s\tremaining: 14m 30s\n",
      "705:\tlearn: 0.4990216\ttotal: 34m 43s\tremaining: 14m 27s\n",
      "706:\tlearn: 0.4990077\ttotal: 34m 45s\tremaining: 14m 24s\n",
      "707:\tlearn: 0.4989958\ttotal: 34m 48s\tremaining: 14m 21s\n",
      "708:\tlearn: 0.4989812\ttotal: 34m 51s\tremaining: 14m 18s\n",
      "709:\tlearn: 0.4989654\ttotal: 34m 54s\tremaining: 14m 15s\n",
      "710:\tlearn: 0.4989507\ttotal: 34m 56s\tremaining: 14m 12s\n",
      "711:\tlearn: 0.4989442\ttotal: 34m 59s\tremaining: 14m 9s\n",
      "712:\tlearn: 0.4989304\ttotal: 35m 2s\tremaining: 14m 6s\n",
      "713:\tlearn: 0.4989172\ttotal: 35m 5s\tremaining: 14m 3s\n",
      "714:\tlearn: 0.4989069\ttotal: 35m 7s\tremaining: 14m\n",
      "715:\tlearn: 0.4988942\ttotal: 35m 10s\tremaining: 13m 57s\n",
      "716:\tlearn: 0.4988815\ttotal: 35m 13s\tremaining: 13m 54s\n",
      "717:\tlearn: 0.4988700\ttotal: 35m 15s\tremaining: 13m 51s\n",
      "718:\tlearn: 0.4988532\ttotal: 35m 18s\tremaining: 13m 48s\n",
      "719:\tlearn: 0.4988441\ttotal: 35m 21s\tremaining: 13m 44s\n",
      "720:\tlearn: 0.4988315\ttotal: 35m 24s\tremaining: 13m 41s\n",
      "721:\tlearn: 0.4988216\ttotal: 35m 26s\tremaining: 13m 38s\n",
      "722:\tlearn: 0.4988113\ttotal: 35m 29s\tremaining: 13m 35s\n",
      "723:\tlearn: 0.4987983\ttotal: 35m 32s\tremaining: 13m 32s\n",
      "724:\tlearn: 0.4987834\ttotal: 35m 35s\tremaining: 13m 29s\n",
      "725:\tlearn: 0.4987691\ttotal: 35m 38s\tremaining: 13m 26s\n",
      "726:\tlearn: 0.4987565\ttotal: 35m 40s\tremaining: 13m 23s\n",
      "727:\tlearn: 0.4987511\ttotal: 35m 43s\tremaining: 13m 20s\n",
      "728:\tlearn: 0.4987341\ttotal: 35m 46s\tremaining: 13m 17s\n",
      "729:\tlearn: 0.4987192\ttotal: 35m 49s\tremaining: 13m 14s\n",
      "730:\tlearn: 0.4987021\ttotal: 35m 51s\tremaining: 13m 11s\n",
      "731:\tlearn: 0.4986976\ttotal: 35m 54s\tremaining: 13m 8s\n",
      "732:\tlearn: 0.4986832\ttotal: 35m 57s\tremaining: 13m 5s\n",
      "733:\tlearn: 0.4986693\ttotal: 36m\tremaining: 13m 2s\n",
      "734:\tlearn: 0.4986623\ttotal: 36m 3s\tremaining: 12m 59s\n",
      "735:\tlearn: 0.4986449\ttotal: 36m 5s\tremaining: 12m 56s\n",
      "736:\tlearn: 0.4986284\ttotal: 36m 8s\tremaining: 12m 53s\n",
      "737:\tlearn: 0.4986069\ttotal: 36m 11s\tremaining: 12m 50s\n",
      "738:\tlearn: 0.4985946\ttotal: 36m 13s\tremaining: 12m 47s\n",
      "739:\tlearn: 0.4985853\ttotal: 36m 16s\tremaining: 12m 44s\n",
      "740:\tlearn: 0.4985741\ttotal: 36m 19s\tremaining: 12m 41s\n",
      "741:\tlearn: 0.4985511\ttotal: 36m 22s\tremaining: 12m 38s\n",
      "742:\tlearn: 0.4985398\ttotal: 36m 25s\tremaining: 12m 35s\n",
      "743:\tlearn: 0.4985258\ttotal: 36m 27s\tremaining: 12m 32s\n",
      "744:\tlearn: 0.4985152\ttotal: 36m 30s\tremaining: 12m 29s\n",
      "745:\tlearn: 0.4984998\ttotal: 36m 33s\tremaining: 12m 26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746:\tlearn: 0.4984783\ttotal: 36m 36s\tremaining: 12m 23s\n",
      "747:\tlearn: 0.4984662\ttotal: 36m 39s\tremaining: 12m 20s\n",
      "748:\tlearn: 0.4984526\ttotal: 36m 41s\tremaining: 12m 17s\n",
      "749:\tlearn: 0.4984429\ttotal: 36m 44s\tremaining: 12m 14s\n",
      "750:\tlearn: 0.4984239\ttotal: 36m 47s\tremaining: 12m 11s\n",
      "751:\tlearn: 0.4984084\ttotal: 36m 50s\tremaining: 12m 8s\n",
      "752:\tlearn: 0.4983934\ttotal: 36m 53s\tremaining: 12m 5s\n",
      "753:\tlearn: 0.4983849\ttotal: 36m 56s\tremaining: 12m 3s\n",
      "754:\tlearn: 0.4983671\ttotal: 36m 58s\tremaining: 12m\n",
      "755:\tlearn: 0.4983594\ttotal: 37m 1s\tremaining: 11m 57s\n",
      "756:\tlearn: 0.4983455\ttotal: 37m 4s\tremaining: 11m 54s\n",
      "757:\tlearn: 0.4983294\ttotal: 37m 7s\tremaining: 11m 51s\n",
      "758:\tlearn: 0.4983155\ttotal: 37m 9s\tremaining: 11m 48s\n",
      "759:\tlearn: 0.4983023\ttotal: 37m 12s\tremaining: 11m 45s\n",
      "760:\tlearn: 0.4982835\ttotal: 37m 15s\tremaining: 11m 42s\n",
      "761:\tlearn: 0.4982648\ttotal: 37m 18s\tremaining: 11m 39s\n",
      "762:\tlearn: 0.4982548\ttotal: 37m 21s\tremaining: 11m 36s\n",
      "763:\tlearn: 0.4982503\ttotal: 37m 24s\tremaining: 11m 33s\n",
      "764:\tlearn: 0.4982329\ttotal: 37m 26s\tremaining: 11m 30s\n",
      "765:\tlearn: 0.4982165\ttotal: 37m 29s\tremaining: 11m 27s\n",
      "766:\tlearn: 0.4982060\ttotal: 37m 32s\tremaining: 11m 24s\n",
      "767:\tlearn: 0.4981933\ttotal: 37m 35s\tremaining: 11m 21s\n",
      "768:\tlearn: 0.4981823\ttotal: 37m 37s\tremaining: 11m 18s\n",
      "769:\tlearn: 0.4981743\ttotal: 37m 40s\tremaining: 11m 15s\n",
      "770:\tlearn: 0.4981543\ttotal: 37m 43s\tremaining: 11m 12s\n",
      "771:\tlearn: 0.4981447\ttotal: 37m 46s\tremaining: 11m 9s\n",
      "772:\tlearn: 0.4981324\ttotal: 37m 49s\tremaining: 11m 6s\n",
      "773:\tlearn: 0.4981130\ttotal: 37m 51s\tremaining: 11m 3s\n",
      "774:\tlearn: 0.4981044\ttotal: 37m 54s\tremaining: 11m\n",
      "775:\tlearn: 0.4980941\ttotal: 37m 57s\tremaining: 10m 57s\n",
      "776:\tlearn: 0.4980785\ttotal: 38m\tremaining: 10m 54s\n",
      "777:\tlearn: 0.4980667\ttotal: 38m 2s\tremaining: 10m 51s\n",
      "778:\tlearn: 0.4980506\ttotal: 38m 5s\tremaining: 10m 48s\n",
      "779:\tlearn: 0.4980442\ttotal: 38m 8s\tremaining: 10m 45s\n",
      "780:\tlearn: 0.4980302\ttotal: 38m 11s\tremaining: 10m 42s\n",
      "781:\tlearn: 0.4980232\ttotal: 38m 13s\tremaining: 10m 39s\n",
      "782:\tlearn: 0.4980163\ttotal: 38m 16s\tremaining: 10m 36s\n",
      "783:\tlearn: 0.4980017\ttotal: 38m 19s\tremaining: 10m 33s\n",
      "784:\tlearn: 0.4979902\ttotal: 38m 22s\tremaining: 10m 30s\n",
      "785:\tlearn: 0.4979860\ttotal: 38m 25s\tremaining: 10m 27s\n",
      "786:\tlearn: 0.4979673\ttotal: 38m 28s\tremaining: 10m 24s\n",
      "787:\tlearn: 0.4979553\ttotal: 38m 30s\tremaining: 10m 21s\n",
      "788:\tlearn: 0.4979428\ttotal: 38m 33s\tremaining: 10m 18s\n",
      "789:\tlearn: 0.4979334\ttotal: 38m 36s\tremaining: 10m 15s\n",
      "790:\tlearn: 0.4979199\ttotal: 38m 39s\tremaining: 10m 12s\n",
      "791:\tlearn: 0.4979024\ttotal: 38m 41s\tremaining: 10m 9s\n",
      "792:\tlearn: 0.4978872\ttotal: 38m 44s\tremaining: 10m 6s\n",
      "793:\tlearn: 0.4978726\ttotal: 38m 47s\tremaining: 10m 3s\n",
      "794:\tlearn: 0.4978631\ttotal: 38m 50s\tremaining: 10m\n",
      "795:\tlearn: 0.4978520\ttotal: 38m 52s\tremaining: 9m 57s\n",
      "796:\tlearn: 0.4978377\ttotal: 38m 55s\tremaining: 9m 54s\n",
      "797:\tlearn: 0.4978260\ttotal: 38m 58s\tremaining: 9m 51s\n",
      "798:\tlearn: 0.4978128\ttotal: 39m 1s\tremaining: 9m 48s\n",
      "799:\tlearn: 0.4977985\ttotal: 39m 3s\tremaining: 9m 46s\n",
      "800:\tlearn: 0.4977846\ttotal: 39m 6s\tremaining: 9m 43s\n",
      "801:\tlearn: 0.4977662\ttotal: 39m 9s\tremaining: 9m 40s\n",
      "802:\tlearn: 0.4977553\ttotal: 39m 12s\tremaining: 9m 37s\n",
      "803:\tlearn: 0.4977432\ttotal: 39m 14s\tremaining: 9m 34s\n",
      "804:\tlearn: 0.4977313\ttotal: 39m 17s\tremaining: 9m 31s\n",
      "805:\tlearn: 0.4977211\ttotal: 39m 20s\tremaining: 9m 28s\n",
      "806:\tlearn: 0.4977089\ttotal: 39m 23s\tremaining: 9m 25s\n",
      "807:\tlearn: 0.4976981\ttotal: 39m 26s\tremaining: 9m 22s\n",
      "808:\tlearn: 0.4976804\ttotal: 39m 29s\tremaining: 9m 19s\n",
      "809:\tlearn: 0.4976691\ttotal: 39m 31s\tremaining: 9m 16s\n",
      "810:\tlearn: 0.4976600\ttotal: 39m 34s\tremaining: 9m 13s\n",
      "811:\tlearn: 0.4976519\ttotal: 39m 37s\tremaining: 9m 10s\n",
      "812:\tlearn: 0.4976396\ttotal: 39m 40s\tremaining: 9m 7s\n",
      "813:\tlearn: 0.4976256\ttotal: 39m 42s\tremaining: 9m 4s\n",
      "814:\tlearn: 0.4976166\ttotal: 39m 45s\tremaining: 9m 1s\n",
      "815:\tlearn: 0.4975995\ttotal: 39m 48s\tremaining: 8m 58s\n",
      "816:\tlearn: 0.4975823\ttotal: 39m 51s\tremaining: 8m 55s\n",
      "817:\tlearn: 0.4975662\ttotal: 39m 54s\tremaining: 8m 52s\n",
      "818:\tlearn: 0.4975560\ttotal: 39m 56s\tremaining: 8m 49s\n",
      "819:\tlearn: 0.4975422\ttotal: 39m 59s\tremaining: 8m 46s\n",
      "820:\tlearn: 0.4975258\ttotal: 40m 2s\tremaining: 8m 43s\n",
      "821:\tlearn: 0.4975176\ttotal: 40m 5s\tremaining: 8m 40s\n",
      "822:\tlearn: 0.4975053\ttotal: 40m 8s\tremaining: 8m 37s\n",
      "823:\tlearn: 0.4974891\ttotal: 40m 10s\tremaining: 8m 34s\n",
      "824:\tlearn: 0.4974732\ttotal: 40m 13s\tremaining: 8m 31s\n",
      "825:\tlearn: 0.4974560\ttotal: 40m 16s\tremaining: 8m 29s\n",
      "826:\tlearn: 0.4974432\ttotal: 40m 19s\tremaining: 8m 26s\n",
      "827:\tlearn: 0.4974303\ttotal: 40m 22s\tremaining: 8m 23s\n",
      "828:\tlearn: 0.4974203\ttotal: 40m 25s\tremaining: 8m 20s\n",
      "829:\tlearn: 0.4974109\ttotal: 40m 27s\tremaining: 8m 17s\n",
      "830:\tlearn: 0.4974028\ttotal: 40m 30s\tremaining: 8m 14s\n",
      "831:\tlearn: 0.4973972\ttotal: 40m 33s\tremaining: 8m 11s\n",
      "832:\tlearn: 0.4973854\ttotal: 40m 36s\tremaining: 8m 8s\n",
      "833:\tlearn: 0.4973680\ttotal: 40m 39s\tremaining: 8m 5s\n",
      "834:\tlearn: 0.4973632\ttotal: 40m 41s\tremaining: 8m 2s\n",
      "835:\tlearn: 0.4973505\ttotal: 40m 44s\tremaining: 7m 59s\n",
      "836:\tlearn: 0.4973385\ttotal: 40m 47s\tremaining: 7m 56s\n",
      "837:\tlearn: 0.4973273\ttotal: 40m 50s\tremaining: 7m 53s\n",
      "838:\tlearn: 0.4973138\ttotal: 40m 53s\tremaining: 7m 50s\n",
      "839:\tlearn: 0.4973013\ttotal: 40m 56s\tremaining: 7m 47s\n",
      "840:\tlearn: 0.4972945\ttotal: 40m 58s\tremaining: 7m 44s\n",
      "841:\tlearn: 0.4972833\ttotal: 41m 1s\tremaining: 7m 41s\n",
      "842:\tlearn: 0.4972702\ttotal: 41m 4s\tremaining: 7m 38s\n",
      "843:\tlearn: 0.4972587\ttotal: 41m 7s\tremaining: 7m 36s\n",
      "844:\tlearn: 0.4972455\ttotal: 41m 10s\tremaining: 7m 33s\n",
      "845:\tlearn: 0.4972388\ttotal: 41m 13s\tremaining: 7m 30s\n",
      "846:\tlearn: 0.4972242\ttotal: 41m 16s\tremaining: 7m 27s\n",
      "847:\tlearn: 0.4972140\ttotal: 41m 19s\tremaining: 7m 24s\n",
      "848:\tlearn: 0.4972059\ttotal: 41m 21s\tremaining: 7m 21s\n",
      "849:\tlearn: 0.4971949\ttotal: 41m 24s\tremaining: 7m 18s\n",
      "850:\tlearn: 0.4971817\ttotal: 41m 27s\tremaining: 7m 15s\n",
      "851:\tlearn: 0.4971682\ttotal: 41m 30s\tremaining: 7m 12s\n",
      "852:\tlearn: 0.4971514\ttotal: 41m 33s\tremaining: 7m 9s\n",
      "853:\tlearn: 0.4971353\ttotal: 41m 36s\tremaining: 7m 6s\n",
      "854:\tlearn: 0.4971262\ttotal: 41m 39s\tremaining: 7m 3s\n",
      "855:\tlearn: 0.4971124\ttotal: 41m 42s\tremaining: 7m\n",
      "856:\tlearn: 0.4970993\ttotal: 41m 45s\tremaining: 6m 58s\n",
      "857:\tlearn: 0.4970901\ttotal: 41m 48s\tremaining: 6m 55s\n",
      "858:\tlearn: 0.4970772\ttotal: 41m 51s\tremaining: 6m 52s\n",
      "859:\tlearn: 0.4970636\ttotal: 41m 54s\tremaining: 6m 49s\n",
      "860:\tlearn: 0.4970531\ttotal: 41m 57s\tremaining: 6m 46s\n",
      "861:\tlearn: 0.4970407\ttotal: 41m 59s\tremaining: 6m 43s\n",
      "862:\tlearn: 0.4970316\ttotal: 42m 2s\tremaining: 6m 40s\n",
      "863:\tlearn: 0.4970231\ttotal: 42m 5s\tremaining: 6m 37s\n",
      "864:\tlearn: 0.4970158\ttotal: 42m 8s\tremaining: 6m 34s\n",
      "865:\tlearn: 0.4970045\ttotal: 42m 11s\tremaining: 6m 31s\n",
      "866:\tlearn: 0.4969966\ttotal: 42m 14s\tremaining: 6m 28s\n",
      "867:\tlearn: 0.4969819\ttotal: 42m 17s\tremaining: 6m 25s\n",
      "868:\tlearn: 0.4969724\ttotal: 42m 20s\tremaining: 6m 22s\n",
      "869:\tlearn: 0.4969604\ttotal: 42m 23s\tremaining: 6m 20s\n",
      "870:\tlearn: 0.4969492\ttotal: 42m 26s\tremaining: 6m 17s\n",
      "871:\tlearn: 0.4969355\ttotal: 42m 29s\tremaining: 6m 14s\n",
      "872:\tlearn: 0.4969261\ttotal: 42m 32s\tremaining: 6m 11s\n",
      "873:\tlearn: 0.4969151\ttotal: 42m 34s\tremaining: 6m 8s\n",
      "874:\tlearn: 0.4969048\ttotal: 42m 37s\tremaining: 6m 5s\n",
      "875:\tlearn: 0.4968908\ttotal: 42m 40s\tremaining: 6m 2s\n",
      "876:\tlearn: 0.4968772\ttotal: 42m 43s\tremaining: 5m 59s\n",
      "877:\tlearn: 0.4968670\ttotal: 42m 45s\tremaining: 5m 56s\n",
      "878:\tlearn: 0.4968558\ttotal: 42m 48s\tremaining: 5m 53s\n",
      "879:\tlearn: 0.4968393\ttotal: 42m 51s\tremaining: 5m 50s\n",
      "880:\tlearn: 0.4968245\ttotal: 42m 54s\tremaining: 5m 47s\n",
      "881:\tlearn: 0.4968134\ttotal: 42m 57s\tremaining: 5m 44s\n",
      "882:\tlearn: 0.4968028\ttotal: 42m 59s\tremaining: 5m 41s\n",
      "883:\tlearn: 0.4967904\ttotal: 43m 2s\tremaining: 5m 38s\n",
      "884:\tlearn: 0.4967841\ttotal: 43m 5s\tremaining: 5m 35s\n",
      "885:\tlearn: 0.4967706\ttotal: 43m 8s\tremaining: 5m 33s\n",
      "886:\tlearn: 0.4967555\ttotal: 43m 10s\tremaining: 5m 30s\n",
      "887:\tlearn: 0.4967448\ttotal: 43m 13s\tremaining: 5m 27s\n",
      "888:\tlearn: 0.4967386\ttotal: 43m 16s\tremaining: 5m 24s\n",
      "889:\tlearn: 0.4967254\ttotal: 43m 19s\tremaining: 5m 21s\n",
      "890:\tlearn: 0.4967088\ttotal: 43m 22s\tremaining: 5m 18s\n",
      "891:\tlearn: 0.4966967\ttotal: 43m 24s\tremaining: 5m 15s\n",
      "892:\tlearn: 0.4966818\ttotal: 43m 27s\tremaining: 5m 12s\n",
      "893:\tlearn: 0.4966730\ttotal: 43m 30s\tremaining: 5m 9s\n",
      "894:\tlearn: 0.4966585\ttotal: 43m 33s\tremaining: 5m 6s\n",
      "895:\tlearn: 0.4966497\ttotal: 43m 36s\tremaining: 5m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896:\tlearn: 0.4966361\ttotal: 43m 39s\tremaining: 5m\n",
      "897:\tlearn: 0.4966270\ttotal: 43m 42s\tremaining: 4m 57s\n",
      "898:\tlearn: 0.4966170\ttotal: 43m 45s\tremaining: 4m 54s\n",
      "899:\tlearn: 0.4966077\ttotal: 43m 48s\tremaining: 4m 52s\n",
      "900:\tlearn: 0.4965940\ttotal: 43m 51s\tremaining: 4m 49s\n",
      "901:\tlearn: 0.4965839\ttotal: 43m 53s\tremaining: 4m 46s\n",
      "902:\tlearn: 0.4965696\ttotal: 43m 56s\tremaining: 4m 43s\n",
      "903:\tlearn: 0.4965603\ttotal: 43m 59s\tremaining: 4m 40s\n",
      "904:\tlearn: 0.4965526\ttotal: 44m 2s\tremaining: 4m 37s\n",
      "905:\tlearn: 0.4965395\ttotal: 44m 5s\tremaining: 4m 34s\n",
      "906:\tlearn: 0.4965258\ttotal: 44m 8s\tremaining: 4m 31s\n",
      "907:\tlearn: 0.4965075\ttotal: 44m 11s\tremaining: 4m 28s\n",
      "908:\tlearn: 0.4964944\ttotal: 44m 14s\tremaining: 4m 25s\n",
      "909:\tlearn: 0.4964822\ttotal: 44m 17s\tremaining: 4m 22s\n",
      "910:\tlearn: 0.4964718\ttotal: 44m 20s\tremaining: 4m 19s\n",
      "911:\tlearn: 0.4964531\ttotal: 44m 23s\tremaining: 4m 16s\n",
      "912:\tlearn: 0.4964403\ttotal: 44m 26s\tremaining: 4m 14s\n",
      "913:\tlearn: 0.4964292\ttotal: 44m 29s\tremaining: 4m 11s\n",
      "914:\tlearn: 0.4964141\ttotal: 44m 32s\tremaining: 4m 8s\n",
      "915:\tlearn: 0.4964040\ttotal: 44m 34s\tremaining: 4m 5s\n",
      "916:\tlearn: 0.4963952\ttotal: 44m 37s\tremaining: 4m 2s\n",
      "917:\tlearn: 0.4963818\ttotal: 44m 40s\tremaining: 3m 59s\n",
      "918:\tlearn: 0.4963673\ttotal: 44m 43s\tremaining: 3m 56s\n",
      "919:\tlearn: 0.4963541\ttotal: 44m 46s\tremaining: 3m 53s\n",
      "920:\tlearn: 0.4963469\ttotal: 44m 49s\tremaining: 3m 50s\n",
      "921:\tlearn: 0.4963368\ttotal: 44m 52s\tremaining: 3m 47s\n",
      "922:\tlearn: 0.4963280\ttotal: 44m 55s\tremaining: 3m 44s\n",
      "923:\tlearn: 0.4963156\ttotal: 44m 58s\tremaining: 3m 41s\n",
      "924:\tlearn: 0.4963042\ttotal: 45m 1s\tremaining: 3m 39s\n",
      "925:\tlearn: 0.4962871\ttotal: 45m 3s\tremaining: 3m 36s\n",
      "926:\tlearn: 0.4962737\ttotal: 45m 6s\tremaining: 3m 33s\n",
      "927:\tlearn: 0.4962603\ttotal: 45m 9s\tremaining: 3m 30s\n",
      "928:\tlearn: 0.4962507\ttotal: 45m 12s\tremaining: 3m 27s\n",
      "929:\tlearn: 0.4962438\ttotal: 45m 14s\tremaining: 3m 24s\n",
      "930:\tlearn: 0.4962289\ttotal: 45m 17s\tremaining: 3m 21s\n",
      "931:\tlearn: 0.4962161\ttotal: 45m 20s\tremaining: 3m 18s\n",
      "932:\tlearn: 0.4962035\ttotal: 45m 23s\tremaining: 3m 15s\n",
      "933:\tlearn: 0.4961958\ttotal: 45m 26s\tremaining: 3m 12s\n",
      "934:\tlearn: 0.4961891\ttotal: 45m 29s\tremaining: 3m 9s\n",
      "935:\tlearn: 0.4961758\ttotal: 45m 32s\tremaining: 3m 6s\n",
      "936:\tlearn: 0.4961657\ttotal: 45m 34s\tremaining: 3m 3s\n",
      "937:\tlearn: 0.4961542\ttotal: 45m 37s\tremaining: 3m\n",
      "938:\tlearn: 0.4961402\ttotal: 45m 40s\tremaining: 2m 58s\n",
      "939:\tlearn: 0.4961314\ttotal: 45m 43s\tremaining: 2m 55s\n",
      "940:\tlearn: 0.4961190\ttotal: 45m 45s\tremaining: 2m 52s\n",
      "941:\tlearn: 0.4961101\ttotal: 45m 48s\tremaining: 2m 49s\n",
      "942:\tlearn: 0.4960935\ttotal: 45m 51s\tremaining: 2m 46s\n",
      "943:\tlearn: 0.4960816\ttotal: 45m 54s\tremaining: 2m 43s\n",
      "944:\tlearn: 0.4960741\ttotal: 45m 57s\tremaining: 2m 40s\n",
      "945:\tlearn: 0.4960658\ttotal: 45m 59s\tremaining: 2m 37s\n",
      "946:\tlearn: 0.4960556\ttotal: 46m 2s\tremaining: 2m 34s\n",
      "947:\tlearn: 0.4960440\ttotal: 46m 5s\tremaining: 2m 31s\n",
      "948:\tlearn: 0.4960326\ttotal: 46m 8s\tremaining: 2m 28s\n",
      "949:\tlearn: 0.4960187\ttotal: 46m 11s\tremaining: 2m 25s\n",
      "950:\tlearn: 0.4960008\ttotal: 46m 14s\tremaining: 2m 22s\n",
      "951:\tlearn: 0.4959879\ttotal: 46m 17s\tremaining: 2m 20s\n",
      "952:\tlearn: 0.4959825\ttotal: 46m 19s\tremaining: 2m 17s\n",
      "953:\tlearn: 0.4959687\ttotal: 46m 22s\tremaining: 2m 14s\n",
      "954:\tlearn: 0.4959568\ttotal: 46m 25s\tremaining: 2m 11s\n",
      "955:\tlearn: 0.4959464\ttotal: 46m 28s\tremaining: 2m 8s\n",
      "956:\tlearn: 0.4959344\ttotal: 46m 30s\tremaining: 2m 5s\n",
      "957:\tlearn: 0.4959204\ttotal: 46m 33s\tremaining: 2m 2s\n",
      "958:\tlearn: 0.4959007\ttotal: 46m 36s\tremaining: 1m 59s\n",
      "959:\tlearn: 0.4958887\ttotal: 46m 39s\tremaining: 1m 56s\n",
      "960:\tlearn: 0.4958757\ttotal: 46m 42s\tremaining: 1m 53s\n",
      "961:\tlearn: 0.4958653\ttotal: 46m 44s\tremaining: 1m 50s\n",
      "962:\tlearn: 0.4958535\ttotal: 46m 47s\tremaining: 1m 47s\n",
      "963:\tlearn: 0.4958365\ttotal: 46m 50s\tremaining: 1m 44s\n",
      "964:\tlearn: 0.4958260\ttotal: 46m 52s\tremaining: 1m 42s\n",
      "965:\tlearn: 0.4958122\ttotal: 46m 55s\tremaining: 1m 39s\n",
      "966:\tlearn: 0.4958019\ttotal: 46m 58s\tremaining: 1m 36s\n",
      "967:\tlearn: 0.4957899\ttotal: 47m 1s\tremaining: 1m 33s\n",
      "968:\tlearn: 0.4957779\ttotal: 47m 4s\tremaining: 1m 30s\n",
      "969:\tlearn: 0.4957634\ttotal: 47m 7s\tremaining: 1m 27s\n",
      "970:\tlearn: 0.4957575\ttotal: 47m 10s\tremaining: 1m 24s\n",
      "971:\tlearn: 0.4957447\ttotal: 47m 13s\tremaining: 1m 21s\n",
      "972:\tlearn: 0.4957318\ttotal: 47m 16s\tremaining: 1m 18s\n",
      "973:\tlearn: 0.4957163\ttotal: 47m 19s\tremaining: 1m 15s\n",
      "974:\tlearn: 0.4957056\ttotal: 47m 22s\tremaining: 1m 12s\n",
      "975:\tlearn: 0.4956934\ttotal: 47m 25s\tremaining: 1m 9s\n",
      "976:\tlearn: 0.4956805\ttotal: 47m 27s\tremaining: 1m 7s\n",
      "977:\tlearn: 0.4956716\ttotal: 47m 30s\tremaining: 1m 4s\n",
      "978:\tlearn: 0.4956608\ttotal: 47m 33s\tremaining: 1m 1s\n",
      "979:\tlearn: 0.4956471\ttotal: 47m 36s\tremaining: 58.3s\n",
      "980:\tlearn: 0.4956287\ttotal: 47m 39s\tremaining: 55.4s\n",
      "981:\tlearn: 0.4956185\ttotal: 47m 42s\tremaining: 52.5s\n",
      "982:\tlearn: 0.4956110\ttotal: 47m 45s\tremaining: 49.6s\n",
      "983:\tlearn: 0.4955976\ttotal: 47m 48s\tremaining: 46.6s\n",
      "984:\tlearn: 0.4955832\ttotal: 47m 51s\tremaining: 43.7s\n",
      "985:\tlearn: 0.4955715\ttotal: 47m 54s\tremaining: 40.8s\n",
      "986:\tlearn: 0.4955607\ttotal: 47m 57s\tremaining: 37.9s\n",
      "987:\tlearn: 0.4955426\ttotal: 48m\tremaining: 35s\n",
      "988:\tlearn: 0.4955301\ttotal: 48m 3s\tremaining: 32.1s\n",
      "989:\tlearn: 0.4955213\ttotal: 48m 6s\tremaining: 29.2s\n",
      "990:\tlearn: 0.4955122\ttotal: 48m 9s\tremaining: 26.2s\n",
      "991:\tlearn: 0.4955056\ttotal: 48m 12s\tremaining: 23.3s\n",
      "992:\tlearn: 0.4954934\ttotal: 48m 15s\tremaining: 20.4s\n",
      "993:\tlearn: 0.4954855\ttotal: 48m 18s\tremaining: 17.5s\n",
      "994:\tlearn: 0.4954765\ttotal: 48m 21s\tremaining: 14.6s\n",
      "995:\tlearn: 0.4954639\ttotal: 48m 24s\tremaining: 11.7s\n",
      "996:\tlearn: 0.4954486\ttotal: 48m 27s\tremaining: 8.75s\n",
      "997:\tlearn: 0.4954326\ttotal: 48m 30s\tremaining: 5.83s\n",
      "998:\tlearn: 0.4954226\ttotal: 48m 33s\tremaining: 2.92s\n",
      "999:\tlearn: 0.4954149\ttotal: 48m 36s\tremaining: 0us\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.83    328170\n",
      "          1       0.73      0.52      0.61    175315\n",
      "\n",
      "avg / total       0.76      0.77      0.76    503485\n",
      "\n",
      "[[294102  34068]\n",
      " [ 83356  91959]]\n",
      "0.7103618934313884\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from catboost import Pool\n",
    "\n",
    "#cat_features = []\n",
    "train_data = X_train\n",
    "train_labels = y_train\n",
    "test_data = X_test\n",
    "\n",
    "p = Pool(X_train, y_train ) #,cat_features=cat_features)\n",
    "\n",
    "model = CatBoostClassifier()#iterations=500, learning_rate=0.5, depth=10, loss_function='Logloss',silent=False)\n",
    "\n",
    "model.fit(p)\n",
    "# Прогноз класса\n",
    "preds_class = model.predict(test_data)\n",
    "# Прогноз вероятности каждого класса\n",
    "preds_proba = model.predict_proba(test_data)\n",
    "\n",
    "# Проверка модели\n",
    "print(metrics.classification_report(y_test, preds_class))\n",
    "print(metrics.confusion_matrix(y_test, preds_class))\n",
    "print(roc_auc_score(y_test, preds_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.90      0.83    328170\n",
      "          1       0.73      0.52      0.61    175315\n",
      "\n",
      "avg / total       0.76      0.77      0.76    503485\n",
      "\n",
      "[[294102  34068]\n",
      " [ 83356  91959]]\n",
      "0.7103618934313884\n"
     ]
    }
   ],
   "source": [
    "# Проверка модели\n",
    "print(metrics.classification_report(y_test, preds_class))\n",
    "print(metrics.confusion_matrix(y_test, preds_class))\n",
    "print(roc_auc_score(y_test, preds_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7618932491281364\n"
     ]
    }
   ],
   "source": [
    "test_probs2 = reg.predict(X_test)\n",
    "print(roc_auc_score(y_test, test_probs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7522285871607588\n"
     ]
    }
   ],
   "source": [
    "test_probs2 = reg.predict(X_test)\n",
    "print(roc_auc_score(y_test, test_probs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.90      0.83    328170\n",
      "          1       0.72      0.48      0.57    175315\n",
      "\n",
      "avg / total       0.75      0.75      0.74    503485\n",
      "\n",
      "[[295351  32819]\n",
      " [ 91828  83487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6881026482613075\n"
     ]
    }
   ],
   "source": [
    "test_probs2 = model.predict(X_test)\n",
    "print(roc_auc_score(y_test, test_probs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model = GradientBoostingClassifier(n_)\n",
    "model.fit(X_train, y_train)\n",
    "#print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.86      0.85    328170\n",
      "          1       0.72      0.70      0.71    175315\n",
      "\n",
      "avg / total       0.80      0.80      0.80    503485\n",
      "\n",
      "[[280827  47343]\n",
      " [ 53209 122106]]\n",
      "0.7761156184001416\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# fit a CART model to the data\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "#print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))\n",
    "#ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight='balanced',\n",
       "           criterion='gini', max_depth=None, max_features='log2',\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=700, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.89      0.83    412957\n",
      "          1       0.70      0.51      0.59    215492\n",
      "\n",
      "avg / total       0.75      0.76      0.75    628449\n",
      "\n",
      "[[366628  46329]\n",
      " [105121 110371]]\n",
      "0.6999964953022748\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# fit a CART model to the data\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "#print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1238871\n",
       "1     646473\n",
       "Name: Metal, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "model = ElasticNetCV()\n",
    "model.fit(X_train, y_train)\n",
    "#print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7517887180717764\n"
     ]
    }
   ],
   "source": [
    "# summarize the fit of the model\n",
    "#print(metrics.classification_report(expected, predicted))\n",
    "#print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "# fit a CART model to the data\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "#print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(roc_auc_score(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
